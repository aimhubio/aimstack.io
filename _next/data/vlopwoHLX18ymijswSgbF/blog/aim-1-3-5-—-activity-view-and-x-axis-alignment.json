{"pageProps":{"post":{"title":"Aim 1.3.5 â€” Activity View and X-axis alignment","date":"2021-02-05T11:16:41.748Z","author":"Gev Soghomonian","description":"Aim v1.3.5 is now available. Thanks to the incredible Aim community for the feedback and support on building democratized open source MLOps tools. Check out the new features [â€¦]","slug":"aim-1-3-5-â€”-activity-view-and-x-axis-alignment","image":"/images/dynamic/1st.gif","draft":false,"categories":["New Releases"],"body":{"raw":"\n\n## Aim Release â€” Activity View and X-axis alignment\n\n[Aim](https://github.com/aimhubio/aim) v1.3.5 is now available. Thanks to the incredible [Aim community](https://discord.com/invite/zXq2NfVdtF) for the feedback and support on building democratized open source AI dev tools.\n\nCheck out the new features at play.aimstack.io\n\nHere are the highlights of the features:\n\n## Activity View on the Dashboard\n\nThe **Activity View** shows the daily experiment runs. With one click you can search each dayâ€™s runs and explore them straight away\n\n**Statistics** displays the overall count of [Experiments and Runs. ](https://github.com/aimhubio/aim#concepts)\n\n![](/images/dynamic/1st.gif \"The new dashboard in action!\")\n\n## **X-axis alignment by epoch**\n\nX-axis alignment adds another layer of superpower for metric comparison. If you have tracked metrics in different time-frequencies (e.g. train loss â€” 1000 steps, validation loss â€” 15 steps) then you can align them by epoch, relative time or absolute time.\n\n![](/images/dynamic/2nd.gif \"No more misaligned metrics!\")\n\n## **Ordering runs both on Explore and on Dashboard**\n\n\n\nNow you can order runs both on the Dashboard and on the Explore. Sort the runs by a hyperparam value of metric value on dashboard and explore.\n\nOn Explore, when sorted by a hyperparam thatâ€™s also used for dividing into subplots, the subplots will be positioned by the hyperparam value too.\n\n![](/images/dynamic/3.gif \"Sort the runs both on Dashboard and Explore!\")\n\n## Learn More\n\n\n\nWe have been working on Aim for the past 6 months and excited to see this much interest from the community.\n\nWe are working tirelessly for adding new community-driven features to Aim (and those features have been doubling every monthÂ ğŸ˜Š). Try out Aim, join theÂ [Aim community](https://aimstack.slack.com/?redir=%2Fssb%2Fredirect), share your feedback.\n\nAnd donâ€™t forget to leaveÂ [Aim](https://github.com/aimhubio/aim)Â a star on GitHub for supportÂ ğŸ™Œ.","html":"<h2>Aim Release â€” Activity View and X-axis alignment</h2>\n<p><a href=\"https://github.com/aimhubio/aim\">Aim</a> v1.3.5 is now available. Thanks to the incredible <a href=\"https://discord.com/invite/zXq2NfVdtF\">Aim community</a> for the feedback and support on building democratized open source AI dev tools.</p>\n<p>Check out the new features at play.aimstack.io</p>\n<p>Here are the highlights of the features:</p>\n<h2>Activity View on the Dashboard</h2>\n<p>The <strong>Activity View</strong> shows the daily experiment runs. With one click you can search each dayâ€™s runs and explore them straight away</p>\n<p><strong>Statistics</strong> displays the overall count of <a href=\"https://github.com/aimhubio/aim#concepts\">Experiments and Runs. </a></p>\n<p><img src=\"/images/dynamic/1st.gif\" alt=\"\" title=\"The new dashboard in action!\"></p>\n<h2><strong>X-axis alignment by epoch</strong></h2>\n<p>X-axis alignment adds another layer of superpower for metric comparison. If you have tracked metrics in different time-frequencies (e.g. train loss â€” 1000 steps, validation loss â€” 15 steps) then you can align them by epoch, relative time or absolute time.</p>\n<p><img src=\"/images/dynamic/2nd.gif\" alt=\"\" title=\"No more misaligned metrics!\"></p>\n<h2><strong>Ordering runs both on Explore and on Dashboard</strong></h2>\n<p>Now you can order runs both on the Dashboard and on the Explore. Sort the runs by a hyperparam value of metric value on dashboard and explore.</p>\n<p>On Explore, when sorted by a hyperparam thatâ€™s also used for dividing into subplots, the subplots will be positioned by the hyperparam value too.</p>\n<p><img src=\"/images/dynamic/3.gif\" alt=\"\" title=\"Sort the runs both on Dashboard and Explore!\"></p>\n<h2>Learn More</h2>\n<p>We have been working on Aim for the past 6 months and excited to see this much interest from the community.</p>\n<p>We are working tirelessly for adding new community-driven features to Aim (and those features have been doubling every monthÂ ğŸ˜Š). Try out Aim, join theÂ <a href=\"https://aimstack.slack.com/?redir=%2Fssb%2Fredirect\">Aim community</a>, share your feedback.</p>\n<p>And donâ€™t forget to leaveÂ <a href=\"https://github.com/aimhubio/aim\">Aim</a>Â a star on GitHub for supportÂ ğŸ™Œ.</p>"},"_id":"aim-1-3-5-â€”-activity-view-and-x-axis-alignment.md","_raw":{"sourceFilePath":"aim-1-3-5-â€”-activity-view-and-x-axis-alignment.md","sourceFileName":"aim-1-3-5-â€”-activity-view-and-x-axis-alignment.md","sourceFileDir":".","contentType":"markdown","flattenedPath":"aim-1-3-5-â€”-activity-view-and-x-axis-alignment"},"type":"Post"},"posts":[{"title":"Aim 1.3.5 â€” Activity View and X-axis alignment","date":"2021-02-05T11:16:41.748Z","author":"Gev Soghomonian","description":"Aim v1.3.5 is now available. Thanks to the incredible Aim community for the feedback and support on building democratized open source MLOps tools. Check out the new features [â€¦]","slug":"aim-1-3-5-â€”-activity-view-and-x-axis-alignment","image":"/images/dynamic/1st.gif","draft":false,"categories":["New Releases"],"body":{"raw":"\n\n## Aim Release â€” Activity View and X-axis alignment\n\n[Aim](https://github.com/aimhubio/aim) v1.3.5 is now available. Thanks to the incredible [Aim community](https://discord.com/invite/zXq2NfVdtF) for the feedback and support on building democratized open source AI dev tools.\n\nCheck out the new features at play.aimstack.io\n\nHere are the highlights of the features:\n\n## Activity View on the Dashboard\n\nThe **Activity View** shows the daily experiment runs. With one click you can search each dayâ€™s runs and explore them straight away\n\n**Statistics** displays the overall count of [Experiments and Runs. ](https://github.com/aimhubio/aim#concepts)\n\n![](/images/dynamic/1st.gif \"The new dashboard in action!\")\n\n## **X-axis alignment by epoch**\n\nX-axis alignment adds another layer of superpower for metric comparison. If you have tracked metrics in different time-frequencies (e.g. train loss â€” 1000 steps, validation loss â€” 15 steps) then you can align them by epoch, relative time or absolute time.\n\n![](/images/dynamic/2nd.gif \"No more misaligned metrics!\")\n\n## **Ordering runs both on Explore and on Dashboard**\n\n\n\nNow you can order runs both on the Dashboard and on the Explore. Sort the runs by a hyperparam value of metric value on dashboard and explore.\n\nOn Explore, when sorted by a hyperparam thatâ€™s also used for dividing into subplots, the subplots will be positioned by the hyperparam value too.\n\n![](/images/dynamic/3.gif \"Sort the runs both on Dashboard and Explore!\")\n\n## Learn More\n\n\n\nWe have been working on Aim for the past 6 months and excited to see this much interest from the community.\n\nWe are working tirelessly for adding new community-driven features to Aim (and those features have been doubling every monthÂ ğŸ˜Š). Try out Aim, join theÂ [Aim community](https://aimstack.slack.com/?redir=%2Fssb%2Fredirect), share your feedback.\n\nAnd donâ€™t forget to leaveÂ [Aim](https://github.com/aimhubio/aim)Â a star on GitHub for supportÂ ğŸ™Œ.","html":"<h2>Aim Release â€” Activity View and X-axis alignment</h2>\n<p><a href=\"https://github.com/aimhubio/aim\">Aim</a> v1.3.5 is now available. Thanks to the incredible <a href=\"https://discord.com/invite/zXq2NfVdtF\">Aim community</a> for the feedback and support on building democratized open source AI dev tools.</p>\n<p>Check out the new features at play.aimstack.io</p>\n<p>Here are the highlights of the features:</p>\n<h2>Activity View on the Dashboard</h2>\n<p>The <strong>Activity View</strong> shows the daily experiment runs. With one click you can search each dayâ€™s runs and explore them straight away</p>\n<p><strong>Statistics</strong> displays the overall count of <a href=\"https://github.com/aimhubio/aim#concepts\">Experiments and Runs. </a></p>\n<p><img src=\"/images/dynamic/1st.gif\" alt=\"\" title=\"The new dashboard in action!\"></p>\n<h2><strong>X-axis alignment by epoch</strong></h2>\n<p>X-axis alignment adds another layer of superpower for metric comparison. If you have tracked metrics in different time-frequencies (e.g. train loss â€” 1000 steps, validation loss â€” 15 steps) then you can align them by epoch, relative time or absolute time.</p>\n<p><img src=\"/images/dynamic/2nd.gif\" alt=\"\" title=\"No more misaligned metrics!\"></p>\n<h2><strong>Ordering runs both on Explore and on Dashboard</strong></h2>\n<p>Now you can order runs both on the Dashboard and on the Explore. Sort the runs by a hyperparam value of metric value on dashboard and explore.</p>\n<p>On Explore, when sorted by a hyperparam thatâ€™s also used for dividing into subplots, the subplots will be positioned by the hyperparam value too.</p>\n<p><img src=\"/images/dynamic/3.gif\" alt=\"\" title=\"Sort the runs both on Dashboard and Explore!\"></p>\n<h2>Learn More</h2>\n<p>We have been working on Aim for the past 6 months and excited to see this much interest from the community.</p>\n<p>We are working tirelessly for adding new community-driven features to Aim (and those features have been doubling every monthÂ ğŸ˜Š). Try out Aim, join theÂ <a href=\"https://aimstack.slack.com/?redir=%2Fssb%2Fredirect\">Aim community</a>, share your feedback.</p>\n<p>And donâ€™t forget to leaveÂ <a href=\"https://github.com/aimhubio/aim\">Aim</a>Â a star on GitHub for supportÂ ğŸ™Œ.</p>"},"_id":"aim-1-3-5-â€”-activity-view-and-x-axis-alignment.md","_raw":{"sourceFilePath":"aim-1-3-5-â€”-activity-view-and-x-axis-alignment.md","sourceFileName":"aim-1-3-5-â€”-activity-view-and-x-axis-alignment.md","sourceFileDir":".","contentType":"markdown","flattenedPath":"aim-1-3-5-â€”-activity-view-and-x-axis-alignment"},"type":"Post"},{"title":"Aim 1.3.8 â€” Enhanced Context Table and Advanced Group Coloring","date":"2021-03-01T11:09:06.858Z","author":"Gev Soghomonian","description":"Aim 1.3.8 featuring Advanced Group Coloring for AI metrics  is now available. ","slug":"aim-1-3-8-â€”-enhanced-context-table-and-advanced-group-coloring","image":"https://miro.medium.com/max/1400/1*l27Xjb6pYIMdEkABLkRBRA.webp","draft":false,"categories":["New Releases"],"body":{"raw":"\n\n[Aim](https://aimstack.io/)Â 1.3.8 is now available. Thanks to the incredible Aim community for the feedback and support on building democratized open-source AI dev tools\n\nCheck out the new features atÂ [play.aimstack.io](http://play.aimstack.io:43900/explore?search=eyJjaGFydCI6eyJzZXR0aW5ncyI6eyJwZXJzaXN0ZW50Ijp7ImRpc3BsYXlPdXRsaWVycyI6ZmFsc2UsInpvb20iOm51bGwsImludGVycG9sYXRlIjpmYWxzZSwiaW5kaWNhdG9yIjpmYWxzZSwieEFsaWdubWVudCI6InN0ZXAiLCJwb2ludHNDb3VudCI6NTB9fSwiZm9jdXNlZCI6eyJjaXJjbGUiOnsiYWN0aXZlIjp0cnVlLCJzdGVwIjoxNCwicnVuSGFzaCI6IjRiY2Y4ZDUyLWZjYTgtMTFlYS05MDJiLTBhMTk1NDdlYmIyZSIsIm1ldHJpY05hbWUiOiJsb3NzIiwidHJhY2VDb250ZXh0IjoiZXlKemRXSnpaWFFpT2lKMFpYTjBJbjAifX19LCJzZWFyY2giOnsicXVlcnkiOiJsb3NzLCBibGV1IGlmIGhwYXJhbXMubGVhcm5pbmdfcmF0ZSAhPSAwLjAwMDAxIGFuZCBjb250ZXh0LnN1YnNldCA9PSB0ZXN0IiwidiI6MX0sImNvbnRleHRGaWx0ZXIiOnsiZ3JvdXBCeUNvbG9yIjpbInBhcmFtcy5kYXRhc2V0LnByZXByb2MiXSwiZ3JvdXBCeVN0eWxlIjpbXSwiZ3JvdXBCeUNoYXJ0IjpbIm1ldHJpYyJdLCJhZ2dyZWdhdGVkIjpmYWxzZSwic2VlZCI6eyJjb2xvciI6MTAsInN0eWxlIjoxMH0sInBlcnNpc3QiOnsiY29sb3IiOmZhbHNlLCJzdHlsZSI6ZmFsc2V9fX0=).\n\nHere are the more notable changes:\n\n### Enhanced Context Table\n\n\n\nThe context table used to not use the screen real-estate effectively â€” an empty line per grouping, non-efficient column management (imagine you have 200 columns to deal with).\n\nSo we have made 3 changes to tackle this problem\n\n### New table groups view\n\nBelow is the new modified look of the table. Here is whatâ€™s changed:\n\n* The empty per group is removed\n* In addition to the group details popover, there is an in-place list group config is available for instant lookup\n\n![](https://miro.medium.com/max/1400/1*l27Xjb6pYIMdEkABLkRBRA.webp \"New improved Aim Context Table on Explore\")\n\n\n\n* **\\[In Progress for next release]**Â Column resize â€” this will allow to manage the wide columns and free much-needed screen real-estate for the data that matters.\n\n### Column Management\n\n\n\nThis feature allows to seamlessly pin the important columns to both sides of the table and hide the useless columns in between.\n\nYou can also re-order the columns by dragging the mid-section up/down.\n\nThis is super-handy when dealing with 100s of columns on the table for parameters.\n\n![](https://miro.medium.com/max/1400/1*71RL39uLxxr3vnxMhn1uKg.webp \"Drag columns left and right to pin, search and disable less important ones\")\n\n\n\n### Advanced Group Coloring\n\n\n\nThis is the latest iteration over the group coloring.\n\n* Now Aim enables persistent coloring mode which makes sure the group with same configuration always receives the same color.\n* You can shuffle the colors in case they arenâ€™t pick to your liking\n* You can pick two different color palette for better distribution of the colors.\n\n  ![](https://miro.medium.com/max/1400/1*2pIoR-ZkaPsQ90UQh2W7Fg.webp \"Effective coloring of the groups is important!\")\n\n  ### Thanks to\n* [mahnerak](https://github.com/mahnerak), Lars,Â [Joe](https://github.com/jafioti)Â for detailed feedback â€” helped us immensely in this iteration.\n\n  ### Learn More\n\n  We have been working on Aim for the past 6 months and excited to see the overwhelming interest from the community.\n\n  Try outÂ [Aim](https://aimstack.io/), join theÂ [Aim community](https://slack.aimstack.io/), share your feedback.\n\n  We are building the next generation of democratized AI dev tools.\n\n  And donâ€™t forget to leaveÂ [Aim](https://aimstack.io/)Â a star on GitHub for support ğŸ™Œ.","html":"<p><a href=\"https://aimstack.io/\">Aim</a>Â 1.3.8 is now available. Thanks to the incredible Aim community for the feedback and support on building democratized open-source AI dev tools</p>\n<p>Check out the new features atÂ <a href=\"http://play.aimstack.io:43900/explore?search=eyJjaGFydCI6eyJzZXR0aW5ncyI6eyJwZXJzaXN0ZW50Ijp7ImRpc3BsYXlPdXRsaWVycyI6ZmFsc2UsInpvb20iOm51bGwsImludGVycG9sYXRlIjpmYWxzZSwiaW5kaWNhdG9yIjpmYWxzZSwieEFsaWdubWVudCI6InN0ZXAiLCJwb2ludHNDb3VudCI6NTB9fSwiZm9jdXNlZCI6eyJjaXJjbGUiOnsiYWN0aXZlIjp0cnVlLCJzdGVwIjoxNCwicnVuSGFzaCI6IjRiY2Y4ZDUyLWZjYTgtMTFlYS05MDJiLTBhMTk1NDdlYmIyZSIsIm1ldHJpY05hbWUiOiJsb3NzIiwidHJhY2VDb250ZXh0IjoiZXlKemRXSnpaWFFpT2lKMFpYTjBJbjAifX19LCJzZWFyY2giOnsicXVlcnkiOiJsb3NzLCBibGV1IGlmIGhwYXJhbXMubGVhcm5pbmdfcmF0ZSAhPSAwLjAwMDAxIGFuZCBjb250ZXh0LnN1YnNldCA9PSB0ZXN0IiwidiI6MX0sImNvbnRleHRGaWx0ZXIiOnsiZ3JvdXBCeUNvbG9yIjpbInBhcmFtcy5kYXRhc2V0LnByZXByb2MiXSwiZ3JvdXBCeVN0eWxlIjpbXSwiZ3JvdXBCeUNoYXJ0IjpbIm1ldHJpYyJdLCJhZ2dyZWdhdGVkIjpmYWxzZSwic2VlZCI6eyJjb2xvciI6MTAsInN0eWxlIjoxMH0sInBlcnNpc3QiOnsiY29sb3IiOmZhbHNlLCJzdHlsZSI6ZmFsc2V9fX0=\">play.aimstack.io</a>.</p>\n<p>Here are the more notable changes:</p>\n<h3>Enhanced Context Table</h3>\n<p>The context table used to not use the screen real-estate effectively â€” an empty line per grouping, non-efficient column management (imagine you have 200 columns to deal with).</p>\n<p>So we have made 3 changes to tackle this problem</p>\n<h3>New table groups view</h3>\n<p>Below is the new modified look of the table. Here is whatâ€™s changed:</p>\n<ul>\n<li>The empty per group is removed</li>\n<li>In addition to the group details popover, there is an in-place list group config is available for instant lookup</li>\n</ul>\n<p><img src=\"https://miro.medium.com/max/1400/1*l27Xjb6pYIMdEkABLkRBRA.webp\" alt=\"\" title=\"New improved Aim Context Table on Explore\"></p>\n<ul>\n<li><strong>[In Progress for next release]</strong>Â Column resize â€” this will allow to manage the wide columns and free much-needed screen real-estate for the data that matters.</li>\n</ul>\n<h3>Column Management</h3>\n<p>This feature allows to seamlessly pin the important columns to both sides of the table and hide the useless columns in between.</p>\n<p>You can also re-order the columns by dragging the mid-section up/down.</p>\n<p>This is super-handy when dealing with 100s of columns on the table for parameters.</p>\n<p><img src=\"https://miro.medium.com/max/1400/1*71RL39uLxxr3vnxMhn1uKg.webp\" alt=\"\" title=\"Drag columns left and right to pin, search and disable less important ones\"></p>\n<h3>Advanced Group Coloring</h3>\n<p>This is the latest iteration over the group coloring.</p>\n<ul>\n<li>\n<p>Now Aim enables persistent coloring mode which makes sure the group with same configuration always receives the same color.</p>\n</li>\n<li>\n<p>You can shuffle the colors in case they arenâ€™t pick to your liking</p>\n</li>\n<li>\n<p>You can pick two different color palette for better distribution of the colors.</p>\n<p><img src=\"https://miro.medium.com/max/1400/1*2pIoR-ZkaPsQ90UQh2W7Fg.webp\" alt=\"\" title=\"Effective coloring of the groups is important!\"></p>\n<h3>Thanks to</h3>\n</li>\n<li>\n<p><a href=\"https://github.com/mahnerak\">mahnerak</a>, Lars,Â <a href=\"https://github.com/jafioti\">Joe</a>Â for detailed feedback â€” helped us immensely in this iteration.</p>\n<h3>Learn More</h3>\n<p>We have been working on Aim for the past 6 months and excited to see the overwhelming interest from the community.</p>\n<p>Try outÂ <a href=\"https://aimstack.io/\">Aim</a>, join theÂ <a href=\"https://slack.aimstack.io/\">Aim community</a>, share your feedback.</p>\n<p>We are building the next generation of democratized AI dev tools.</p>\n<p>And donâ€™t forget to leaveÂ <a href=\"https://aimstack.io/\">Aim</a>Â a star on GitHub for support ğŸ™Œ.</p>\n</li>\n</ul>"},"_id":"aim-1-3-8-â€”-enhanced-context-table-and-advanced-group-coloring.md","_raw":{"sourceFilePath":"aim-1-3-8-â€”-enhanced-context-table-and-advanced-group-coloring.md","sourceFileName":"aim-1-3-8-â€”-enhanced-context-table-and-advanced-group-coloring.md","sourceFileDir":".","contentType":"markdown","flattenedPath":"aim-1-3-8-â€”-enhanced-context-table-and-advanced-group-coloring"},"type":"Post"},{"title":"Aim 2.4.0 is out! XGBoost integration, Confidence interval aggregation and lots of UI performance improvements!","date":"2021-05-18T13:58:29.035Z","author":"Gev Soghomonian","description":"Aim 2.4.0 is out! XGBoost integration, Confidence interval aggregation and lots of UI performance improvements!","slug":"aim-2-4-0-is-out-xgboost-integration-confidence-interval-aggregation-and-lots-of-ui-performance-improvements","image":"https://aimstack.io/wp-content/uploads/2022/02/xgboost.png","draft":false,"categories":["New Releases"],"body":{"raw":"[Aim](https://github.com/aimhubio/aim)Â 2.4.0 featuring XGBoost Integration is out ! Thanks to the community for feedback and support on our journey towards democratizing MLOps tools.\n\nCheck out the updated Aim atÂ [play.aimstack.io](http://play.aimstack.io:43900/explore?search=eyJjaGFydCI6eyJzZXR0aW5ncyI6eyJwZXJzaXN0ZW50Ijp7ImRpc3BsYXlPdXRsaWVycyI6ZmFsc2UsInpvb20iOm51bGwsImludGVycG9sYXRlIjp0cnVlLCJpbmRpY2F0b3IiOmZhbHNlLCJ4QWxpZ25tZW50Ijoic3RlcCIsInhTY2FsZSI6MCwieVNjYWxlIjowLCJwb2ludHNDb3VudCI6NTAsInNtb290aGluZ0FsZ29yaXRobSI6ImVtYSIsInNtb290aEZhY3RvciI6MC40NSwiYWdncmVnYXRlZCI6dHJ1ZX19LCJmb2N1c2VkIjp7ImNpcmNsZSI6eyJydW5IYXNoIjpudWxsLCJtZXRyaWNOYW1lIjpudWxsLCJ0cmFjZUNvbnRleHQiOm51bGx9fX0sInNlYXJjaCI6eyJxdWVyeSI6ImJsZXUsIGxvc3MgaWYgY29udGV4dC5zdWJzZXQgPT0gdGVzdCBhbmQgaHBhcmFtcy5sZWFybmluZ19yYXRlID4gMC4wMDAwMSIsInYiOjF9LCJjb250ZXh0RmlsdGVyIjp7Imdyb3VwQnlDb2xvciI6WyJwYXJhbXMuaHBhcmFtcy5tYXhfayJdLCJncm91cEJ5U3R5bGUiOltdLCJncm91cEJ5Q2hhcnQiOlsibWV0cmljIl0sImdyb3VwQWdhaW5zdCI6eyJjb2xvciI6ZmFsc2UsInN0eWxlIjpmYWxzZSwiY2hhcnQiOmZhbHNlfSwiYWdncmVnYXRlZEFyZWEiOiJzdGRfZGV2IiwiYWdncmVnYXRlZExpbmUiOiJtZWRpYW4iLCJzZWVkIjp7ImNvbG9yIjoxMCwic3R5bGUiOjEwfSwicGVyc2lzdCI6eyJjb2xvciI6ZmFsc2UsInN0eWxlIjpmYWxzZX0sImFnZ3JlZ2F0ZWQiOnRydWV9fQ==).\n\nFor this release, there have been lots of performance updates and small tweaks to the UI. Above all, this post highlights the two features of Aim 2.4.0. Please see the full list of changesÂ [here](https://github.com/aimhubio/aim/milestone/6?closed=1).\n\n## XGBoost Inegration\n\n\n\nTo begin with, Â `aim.callback`Â is now available that exportsÂ `AimCallback`Â to be passed to theÂ `xgb.train`Â as a callback to log the experiments.\n\nCheck out thisÂ [blogpost](https://aimstack.io/blog/tutorials/an-end-to-end-example-of-aim-logger-used-with-xgboost-library/)Â for additional details on how to integrate Aim to your XGBoost code.\n\n## Confidence Interval as the aggregation method\n\n![](https://aimstack.io/wp-content/uploads/2022/02/confidence_interval.png)\n\nNow you can use confidence intervals for aggregation. The community has been requesting this feature, since it completes the list of necessary aggregation methods. As a result, if you have outlier metrics in your group, confidence interval will show logical aggregation and get better comparison of the groups.Â \n\n## Learn More\n\n\n\n[Aim is on a mission to democratize AI dev tools.](https://github.com/aimhubio/aim#democratizing-ai-dev-tools)\n\nWe have been incredibly lucky to get help and contributions from the amazing Aim community. Itâ€™s humbling and inspiring.\n\nCheck out the latestÂ [Aim integration](https://aimstack.io/aim-v2-2-0-hugging-face-integration/)!\n\nTry outÂ [Aim](https://github.com/aimhubio/aim), join theÂ [Aim community](https://join.slack.com/t/aimstack/shared_invite/zt-193hk43nr-vmi7zQkLwoxQXn8LW9CQWQ), share your feedback, open issues for new features, bugs.\n\nAnd donâ€™t forget to leaveÂ [Aim](https://github.com/aimhubio/aim)Â a star on GitHub for support.","html":"<p><a href=\"https://github.com/aimhubio/aim\">Aim</a>Â 2.4.0 featuring XGBoost Integration is out ! Thanks to the community for feedback and support on our journey towards democratizing MLOps tools.</p>\n<p>Check out the updated Aim atÂ <a href=\"http://play.aimstack.io:43900/explore?search=eyJjaGFydCI6eyJzZXR0aW5ncyI6eyJwZXJzaXN0ZW50Ijp7ImRpc3BsYXlPdXRsaWVycyI6ZmFsc2UsInpvb20iOm51bGwsImludGVycG9sYXRlIjp0cnVlLCJpbmRpY2F0b3IiOmZhbHNlLCJ4QWxpZ25tZW50Ijoic3RlcCIsInhTY2FsZSI6MCwieVNjYWxlIjowLCJwb2ludHNDb3VudCI6NTAsInNtb290aGluZ0FsZ29yaXRobSI6ImVtYSIsInNtb290aEZhY3RvciI6MC40NSwiYWdncmVnYXRlZCI6dHJ1ZX19LCJmb2N1c2VkIjp7ImNpcmNsZSI6eyJydW5IYXNoIjpudWxsLCJtZXRyaWNOYW1lIjpudWxsLCJ0cmFjZUNvbnRleHQiOm51bGx9fX0sInNlYXJjaCI6eyJxdWVyeSI6ImJsZXUsIGxvc3MgaWYgY29udGV4dC5zdWJzZXQgPT0gdGVzdCBhbmQgaHBhcmFtcy5sZWFybmluZ19yYXRlID4gMC4wMDAwMSIsInYiOjF9LCJjb250ZXh0RmlsdGVyIjp7Imdyb3VwQnlDb2xvciI6WyJwYXJhbXMuaHBhcmFtcy5tYXhfayJdLCJncm91cEJ5U3R5bGUiOltdLCJncm91cEJ5Q2hhcnQiOlsibWV0cmljIl0sImdyb3VwQWdhaW5zdCI6eyJjb2xvciI6ZmFsc2UsInN0eWxlIjpmYWxzZSwiY2hhcnQiOmZhbHNlfSwiYWdncmVnYXRlZEFyZWEiOiJzdGRfZGV2IiwiYWdncmVnYXRlZExpbmUiOiJtZWRpYW4iLCJzZWVkIjp7ImNvbG9yIjoxMCwic3R5bGUiOjEwfSwicGVyc2lzdCI6eyJjb2xvciI6ZmFsc2UsInN0eWxlIjpmYWxzZX0sImFnZ3JlZ2F0ZWQiOnRydWV9fQ==\">play.aimstack.io</a>.</p>\n<p>For this release, there have been lots of performance updates and small tweaks to the UI. Above all, this post highlights the two features of Aim 2.4.0. Please see the full list of changesÂ <a href=\"https://github.com/aimhubio/aim/milestone/6?closed=1\">here</a>.</p>\n<h2>XGBoost Inegration</h2>\n<p>To begin with, Â <code>aim.callback</code>Â is now available that exportsÂ <code>AimCallback</code>Â to be passed to theÂ <code>xgb.train</code>Â as a callback to log the experiments.</p>\n<p>Check out thisÂ <a href=\"https://aimstack.io/blog/tutorials/an-end-to-end-example-of-aim-logger-used-with-xgboost-library/\">blogpost</a>Â for additional details on how to integrate Aim to your XGBoost code.</p>\n<h2>Confidence Interval as the aggregation method</h2>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2022/02/confidence_interval.png\" alt=\"\"></p>\n<p>Now you can use confidence intervals for aggregation. The community has been requesting this feature, since it completes the list of necessary aggregation methods. As a result, if you have outlier metrics in your group, confidence interval will show logical aggregation and get better comparison of the groups.Â </p>\n<h2>Learn More</h2>\n<p><a href=\"https://github.com/aimhubio/aim#democratizing-ai-dev-tools\">Aim is on a mission to democratize AI dev tools.</a></p>\n<p>We have been incredibly lucky to get help and contributions from the amazing Aim community. Itâ€™s humbling and inspiring.</p>\n<p>Check out the latestÂ <a href=\"https://aimstack.io/aim-v2-2-0-hugging-face-integration/\">Aim integration</a>!</p>\n<p>Try outÂ <a href=\"https://github.com/aimhubio/aim\">Aim</a>, join theÂ <a href=\"https://join.slack.com/t/aimstack/shared_invite/zt-193hk43nr-vmi7zQkLwoxQXn8LW9CQWQ\">Aim community</a>, share your feedback, open issues for new features, bugs.</p>\n<p>And donâ€™t forget to leaveÂ <a href=\"https://github.com/aimhubio/aim\">Aim</a>Â a star on GitHub for support.</p>"},"_id":"aim-2-4-0-is-out-xgboost-integration-confidence-interval-aggregation-and-lots-of-ui-performance-improvements.md","_raw":{"sourceFilePath":"aim-2-4-0-is-out-xgboost-integration-confidence-interval-aggregation-and-lots-of-ui-performance-improvements.md","sourceFileName":"aim-2-4-0-is-out-xgboost-integration-confidence-interval-aggregation-and-lots-of-ui-performance-improvements.md","sourceFileDir":".","contentType":"markdown","flattenedPath":"aim-2-4-0-is-out-xgboost-integration-confidence-interval-aggregation-and-lots-of-ui-performance-improvements"},"type":"Post"},{"title":"Aim basics: using context and subplots to compare validation and test metrics","date":"2021-02-16T12:18:06.528Z","author":"Gev Soghomonian","description":"Validation and test metrics comparison is a crucial step in ML experiments. ML researchers divide datasets into three subsets â€” train, validation and test so they can test their model","slug":"aim-basics-using-context-and-subplots-to-compare-validation-and-test-metrics","image":"/images/dynamic/1.gif","draft":false,"categories":["Tutorials"],"body":{"raw":"Researchers divide datasets into three subsets â€” train, validation and test so they can test their model performance at different levels.\n\nThe model is trained on the train subset and subsequent metrics are collected to evaluate how well the training is going. Loss, accuracy and other metrics are computed.\n\nThe validation and test sets are used to test the model on additional unseen data to verify how well it generalise.\n\nModels are usually ran on validation subset after each epoch.\\\nOnce the training is done, models are tested on the test subset to verify the final performance and generalisation.\n\nThere is a need to collect and effectively compare all these metrics.\n\nHere is how to do that onÂ [Aim](https://github.com/aimhubio/aim)\n\n# Using context to track for different subsets?\n\nUse theÂ [aim.track](https://github.com/aimhubio/aim#track)Â context arguments to pass additional information about the metrics. All context parameters can be used to query, group and do other operations on top of the metrics.\n\n![](<script src=\"https://gist.github.com/SGevorg/e08524b3538d3f71d14bf1857a7bc6e9.js\"></script> \"Here is how it looks like on the code\")\n\nOnce the training is ran, executeÂ `aim up`Â in your terminal and start the Aim UI.\n\n# Using subplots to compare test, val loss and bleu metrics\n\n> **\\*Note:**Â The bleu metric is used here instead of accuracy as we are looking at Neural Machine Translation experiments. But this works with every other metric too.*\n\nLetâ€™s go step-by-step on how to break down lots of experiments using subplots.\n\n**Step 1.**Â Explore the runs, the context table, play with the query language.\n\n![](/images/dynamic/1_tfc_fuc-axk07z3-a7jsmg.gif \"Explore the training runs\")\n\n**Step 2.**Â Add theÂ `bleu`Â metric to the Select input â€” query both metrics at the same time. Divide into subplots by metric.\n\n![](https://miro.medium.com/max/1400/1*BQK8qGoG3v4KMpssvzC0hw.gif \"Divide into subplots by metric\")\n\n**Step 3.**Â Search byÂ `context.subset`Â to show bothÂ `test`Â andÂ `val`Â `loss`Â andÂ `bleu`Â metrics. Divide into subplots further byÂ `context.subset`Â too so Aim UI showsÂ `test`Â andÂ `val`Â metrics on different subplots for better comparison.\n\n![](https://miro.medium.com/max/1400/1*fSm2PyNwbcBaAoZceq6Qsw.gif \"Divide into subplots by context / subset\")\n\nNot itâ€™s easy and straightforward to simultaneously compare both 4 metrics and find the best version of the model.\n\n# Summary\n\nHere is a full summary video on how to do it on the UI.\n\n![](https://www.youtube.com/watch?v=DGI8S7SUfEk)\n\n# Learn More\n\nIf you find Aim useful, support us andÂ [star the project](https://github.com/aimhubio/aim)Â on GitHub. Join theÂ [Aim community](https://slack.aimstack.io/)Â and share more about your use-cases and how we can improve Aim to suit them.","html":"<p>Researchers divide datasets into three subsets â€” train, validation and test so they can test their model performance at different levels.</p>\n<p>The model is trained on the train subset and subsequent metrics are collected to evaluate how well the training is going. Loss, accuracy and other metrics are computed.</p>\n<p>The validation and test sets are used to test the model on additional unseen data to verify how well it generalise.</p>\n<p>Models are usually ran on validation subset after each epoch.<br>\nOnce the training is done, models are tested on the test subset to verify the final performance and generalisation.</p>\n<p>There is a need to collect and effectively compare all these metrics.</p>\n<p>Here is how to do that onÂ <a href=\"https://github.com/aimhubio/aim\">Aim</a></p>\n<h1>Using context to track for different subsets?</h1>\n<p>Use theÂ <a href=\"https://github.com/aimhubio/aim#track\">aim.track</a>Â context arguments to pass additional information about the metrics. All context parameters can be used to query, group and do other operations on top of the metrics.</p>\n<p>![]( \"Here is how it looks like on the code\")</p>\n<p>Once the training is ran, executeÂ <code>aim up</code>Â in your terminal and start the Aim UI.</p>\n<h1>Using subplots to compare test, val loss and bleu metrics</h1>\n<blockquote>\n<p><strong>*Note:</strong>Â The bleu metric is used here instead of accuracy as we are looking at Neural Machine Translation experiments. But this works with every other metric too.*</p>\n</blockquote>\n<p>Letâ€™s go step-by-step on how to break down lots of experiments using subplots.</p>\n<p><strong>Step 1.</strong>Â Explore the runs, the context table, play with the query language.</p>\n<p><img src=\"/images/dynamic/1_tfc_fuc-axk07z3-a7jsmg.gif\" alt=\"\" title=\"Explore the training runs\"></p>\n<p><strong>Step 2.</strong>Â Add theÂ <code>bleu</code>Â metric to the Select input â€” query both metrics at the same time. Divide into subplots by metric.</p>\n<p><img src=\"https://miro.medium.com/max/1400/1*BQK8qGoG3v4KMpssvzC0hw.gif\" alt=\"\" title=\"Divide into subplots by metric\"></p>\n<p><strong>Step 3.</strong>Â Search byÂ <code>context.subset</code>Â to show bothÂ <code>test</code>Â andÂ <code>val</code>Â <code>loss</code>Â andÂ <code>bleu</code>Â metrics. Divide into subplots further byÂ <code>context.subset</code>Â too so Aim UI showsÂ <code>test</code>Â andÂ <code>val</code>Â metrics on different subplots for better comparison.</p>\n<p><img src=\"https://miro.medium.com/max/1400/1*fSm2PyNwbcBaAoZceq6Qsw.gif\" alt=\"\" title=\"Divide into subplots by context / subset\"></p>\n<p>Not itâ€™s easy and straightforward to simultaneously compare both 4 metrics and find the best version of the model.</p>\n<h1>Summary</h1>\n<p>Here is a full summary video on how to do it on the UI.</p>\n<p><img src=\"https://www.youtube.com/watch?v=DGI8S7SUfEk\" alt=\"\"></p>\n<h1>Learn More</h1>\n<p>If you find Aim useful, support us andÂ <a href=\"https://github.com/aimhubio/aim\">star the project</a>Â on GitHub. Join theÂ <a href=\"https://slack.aimstack.io/\">Aim community</a>Â and share more about your use-cases and how we can improve Aim to suit them.</p>"},"_id":"aim-basics-using-context-and-subplots-to-compare-validation-and-test-metrics.md","_raw":{"sourceFilePath":"aim-basics-using-context-and-subplots-to-compare-validation-and-test-metrics.md","sourceFileName":"aim-basics-using-context-and-subplots-to-compare-validation-and-test-metrics.md","sourceFileDir":".","contentType":"markdown","flattenedPath":"aim-basics-using-context-and-subplots-to-compare-validation-and-test-metrics"},"type":"Post"},{"title":"Aim v2.2.0 â€” Hugging Face integration","date":"2021-03-24T13:20:24.937Z","author":"Gev Soghomonian","description":"Aim 2.2.0 featuring Hugging Face integration is out! Thanks to the incredible Aim community for the feedback and support on building democratized open-source AI dev tools.","slug":"aim-v2-2-0-â€”-hugging-face-integration","image":"https://aimstack.io/wp-content/uploads/2022/02/HF.png","draft":false,"categories":["New Releases"],"body":{"raw":"[Aim](https://github.com/aimhubio/aim)Â 2.2.0 featuring Hugging Face integration is out! Thanks to the incredible Aim community for the feedback and support on building democratized open-source AI dev tools.\n\nThanks toÂ [siddk](https://github.com/siddk),Â [TommasoBendinelli](https://github.com/TommasoBendinelli)Â andÂ [Khazhak](https://github.com/Khazhak)Â for their contribution to this release.\n\n> **Note on the Aim versioning:**Â The previous two release posts:Â [Aim 1.3.5](https://aimstack.io/blog/new-releases/mlops-tools-aim-1-3-5-activity-view-and-x-axis-alignment/)Â andÂ [Aim 1.3.8](https://aimstack.io/blog/new-releases/aim-1-3-8-enhanced-context-table-and-advanced-group-coloring/)Â had used the version number ofÂ [AimUI](https://aimstack.readthedocs.io/en/latest/ui/overview.html)Â as those contained only UI changes. From now on we are going to stick to the Aim versions only regardless of the type of changes to avoid any confusion.Â [Check out the Aim CHANGELOG](https://github.com/aimhubio/aim/blob/main/CHANGELOG.md).\n\nWe have also addedÂ [milestones](https://github.com/aimhubio/aim/milestones)Â for each version. As well as theÂ [Roadmap](https://github.com/aimhubio/aim#roadmap).\n\nCheck out the new features atÂ [play.aimstack.io](http://play.aimstack.io:43900/dashboard).\n\n## Hugging Face integration\n\nHugging Face integration has been one of the most requested features so far and we are excited to finally ship it. Here is a code snippet of easy it is to integrate Aim and Hugging Face.\n\n```\nfrom aim.hugging_face import AimCallback\nfrom transformers import Trainer\n\naim_callback = AimCallback(repo='/log/dir/path', experiment='your_experiment_name')\n\ntrainer = Trainer(\n       model=model,\n       args=training_args,\n       callbacks=[aim_callback]\n    )\n```\n\nHere is how it works:Â `aim_callback`Â will automatically open an AimÂ `Session`Â and close it when the trainer is done. WhenÂ `trainer.train()`,Â `trainer.evaluate()`Â orÂ `trainer.predict()`Â is called,Â `aim_callback`Â will automatically log the hyper-params and respective metrics.\n\nFind a full exampleÂ [here](https://github.com/aimhubio/aim/blob/main/examples/hugging_face_track.py).\n\n## Metric Visibility Control\n\nWhen dealing with lots of experiments some metrics may need hide (while still being in the Search) to allow better visibility of the overall picture.\n\nA toggle is now available both for each metric/row as well as for global on/off. Check out the demo below:\n\n![](https://aimstack.io/wp-content/uploads/2022/02/demo.gif \"Hide individual metrics as well as collectively\")\n\n## Column resize\n\n\n\nWith lots of params tracked, some of them are too wide for table and take over the whole screen real estate. Column resize will allow to fully control data width on the table.Â Resize is available both on Explore and Dashboard tables.Here is a quick demo:\n\n![](https://aimstack.io/wp-content/uploads/2022/02/demo2.gif \"Drag column edges back-and-forth to resize\")\n\n## Hide columns with similar values\n\n\n\nMore often than not params have lots of repetition. Especially when tracking 100s of them. In that case the explore table becomes super-noisy.\n\nThis feature allows showing only the relevant info. This has been certainly the missing piece of the column management that many had requested. Here is a quick demo:\n\n![](https://aimstack.io/wp-content/uploads/2022/02/demo3.gif \"Leave only different columns with a button click, if needed customize afterwards\")\n\n## Logscale\n\n\n\nOne of the must-have features that we hadnâ€™t had a chance to work on. Finally itâ€™s available!!\n\n![](https://aimstack.io/wp-content/uploads/2022/02/demo4.gif \"log-scale on Aim\")\n\n## New methods for aggregation\n\n\n\nNow you can select different types of aggregations as well as whether to see the whole area or just the aggregated lines.\n\n![](https://aimstack.io/wp-content/uploads/2022/02/demo5.gif)\n\n## Learn More\n\n[Aim is on the mission to democratize AI dev tools.](https://github.com/aimhubio/aim#democratizing-ai-dev-tools)\n\nWe have been incredibly lucky to get help and contributions from the amazing Aim community. Itâ€™s humbling and inspiring.\n\nTry outÂ [Aim](https://github.com/aimhubio/aim), join theÂ [Aim community](https://slack.aimstack.io/), share your feedback.\n\nAnd donâ€™t forget to leaveÂ [Aim](https://github.com/aimhubio/aim)Â a star on GitHub for supportÂ ğŸ™Œ.","html":"<p><a href=\"https://github.com/aimhubio/aim\">Aim</a>Â 2.2.0 featuring Hugging Face integration is out! Thanks to the incredible Aim community for the feedback and support on building democratized open-source AI dev tools.</p>\n<p>Thanks toÂ <a href=\"https://github.com/siddk\">siddk</a>,Â <a href=\"https://github.com/TommasoBendinelli\">TommasoBendinelli</a>Â andÂ <a href=\"https://github.com/Khazhak\">Khazhak</a>Â for their contribution to this release.</p>\n<blockquote>\n<p><strong>Note on the Aim versioning:</strong>Â The previous two release posts:Â <a href=\"https://aimstack.io/blog/new-releases/mlops-tools-aim-1-3-5-activity-view-and-x-axis-alignment/\">Aim 1.3.5</a>Â andÂ <a href=\"https://aimstack.io/blog/new-releases/aim-1-3-8-enhanced-context-table-and-advanced-group-coloring/\">Aim 1.3.8</a>Â had used the version number ofÂ <a href=\"https://aimstack.readthedocs.io/en/latest/ui/overview.html\">AimUI</a>Â as those contained only UI changes. From now on we are going to stick to the Aim versions only regardless of the type of changes to avoid any confusion.Â <a href=\"https://github.com/aimhubio/aim/blob/main/CHANGELOG.md\">Check out the Aim CHANGELOG</a>.</p>\n</blockquote>\n<p>We have also addedÂ <a href=\"https://github.com/aimhubio/aim/milestones\">milestones</a>Â for each version. As well as theÂ <a href=\"https://github.com/aimhubio/aim#roadmap\">Roadmap</a>.</p>\n<p>Check out the new features atÂ <a href=\"http://play.aimstack.io:43900/dashboard\">play.aimstack.io</a>.</p>\n<h2>Hugging Face integration</h2>\n<p>Hugging Face integration has been one of the most requested features so far and we are excited to finally ship it. Here is a code snippet of easy it is to integrate Aim and Hugging Face.</p>\n<pre><code>from aim.hugging_face import AimCallback\nfrom transformers import Trainer\n\naim_callback = AimCallback(repo='/log/dir/path', experiment='your_experiment_name')\n\ntrainer = Trainer(\n       model=model,\n       args=training_args,\n       callbacks=[aim_callback]\n    )\n</code></pre>\n<p>Here is how it works:Â <code>aim_callback</code>Â will automatically open an AimÂ <code>Session</code>Â and close it when the trainer is done. WhenÂ <code>trainer.train()</code>,Â <code>trainer.evaluate()</code>Â orÂ <code>trainer.predict()</code>Â is called,Â <code>aim_callback</code>Â will automatically log the hyper-params and respective metrics.</p>\n<p>Find a full exampleÂ <a href=\"https://github.com/aimhubio/aim/blob/main/examples/hugging_face_track.py\">here</a>.</p>\n<h2>Metric Visibility Control</h2>\n<p>When dealing with lots of experiments some metrics may need hide (while still being in the Search) to allow better visibility of the overall picture.</p>\n<p>A toggle is now available both for each metric/row as well as for global on/off. Check out the demo below:</p>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2022/02/demo.gif\" alt=\"\" title=\"Hide individual metrics as well as collectively\"></p>\n<h2>Column resize</h2>\n<p>With lots of params tracked, some of them are too wide for table and take over the whole screen real estate. Column resize will allow to fully control data width on the table.Â Resize is available both on Explore and Dashboard tables.Here is a quick demo:</p>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2022/02/demo2.gif\" alt=\"\" title=\"Drag column edges back-and-forth to resize\"></p>\n<h2>Hide columns with similar values</h2>\n<p>More often than not params have lots of repetition. Especially when tracking 100s of them. In that case the explore table becomes super-noisy.</p>\n<p>This feature allows showing only the relevant info. This has been certainly the missing piece of the column management that many had requested. Here is a quick demo:</p>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2022/02/demo3.gif\" alt=\"\" title=\"Leave only different columns with a button click, if needed customize afterwards\"></p>\n<h2>Logscale</h2>\n<p>One of the must-have features that we hadnâ€™t had a chance to work on. Finally itâ€™s available!!</p>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2022/02/demo4.gif\" alt=\"\" title=\"log-scale on Aim\"></p>\n<h2>New methods for aggregation</h2>\n<p>Now you can select different types of aggregations as well as whether to see the whole area or just the aggregated lines.</p>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2022/02/demo5.gif\" alt=\"\"></p>\n<h2>Learn More</h2>\n<p><a href=\"https://github.com/aimhubio/aim#democratizing-ai-dev-tools\">Aim is on the mission to democratize AI dev tools.</a></p>\n<p>We have been incredibly lucky to get help and contributions from the amazing Aim community. Itâ€™s humbling and inspiring.</p>\n<p>Try outÂ <a href=\"https://github.com/aimhubio/aim\">Aim</a>, join theÂ <a href=\"https://slack.aimstack.io/\">Aim community</a>, share your feedback.</p>\n<p>And donâ€™t forget to leaveÂ <a href=\"https://github.com/aimhubio/aim\">Aim</a>Â a star on GitHub for supportÂ ğŸ™Œ.</p>"},"_id":"aim-v2-2-0-â€”-hugging-face-integration.md","_raw":{"sourceFilePath":"aim-v2-2-0-â€”-hugging-face-integration.md","sourceFileName":"aim-v2-2-0-â€”-hugging-face-integration.md","sourceFileDir":".","contentType":"markdown","flattenedPath":"aim-v2-2-0-â€”-hugging-face-integration"},"type":"Post"},{"title":"Aim v2.3.0 â€” System Resource Usage and Reverse Grouping","date":"2021-04-20T13:39:39.516Z","author":"Gev Soghomonian","description":"Aim 2.3.0 allowing System Resource Usage optimization is out! Thanks to the community for feedback and support on our journey towards democratizing MLOps tools. Check out...","slug":"aim-v2-3-0-â€”-system-resource-usage-and-reverse-grouping","image":"https://aimstack.io/wp-content/uploads/2021/04/2.3.0-1.png","draft":false,"categories":["New Releases"],"body":{"raw":"[Aim](https://github.com/aimhubio/aim)Â 2.3.0 is out! Thanks to the community for feedback and support on our journey towards democratizing AI dev tools.\n\nCheck out the updated Aim atÂ [play.aimstack.io](http://play.aimstack.io:43900/explore?search=eyJjaGFydCI6eyJzZXR0aW5ncyI6eyJwZXJzaXN0ZW50Ijp7ImRpc3BsYXlPdXRsaWVycyI6ZmFsc2UsInpvb20iOm51bGwsImludGVycG9sYXRlIjp0cnVlLCJpbmRpY2F0b3IiOmZhbHNlLCJ4QWxpZ25tZW50Ijoic3RlcCIsInhTY2FsZSI6MCwieVNjYWxlIjowLCJwb2ludHNDb3VudCI6NTAsInNtb290aGluZ0FsZ29yaXRobSI6ImVtYSIsInNtb290aEZhY3RvciI6MC40NSwiYWdncmVnYXRlZCI6dHJ1ZX19LCJmb2N1c2VkIjp7ImNpcmNsZSI6eyJydW5IYXNoIjpudWxsLCJtZXRyaWNOYW1lIjpudWxsLCJ0cmFjZUNvbnRleHQiOm51bGx9fX0sInNlYXJjaCI6eyJxdWVyeSI6ImJsZXUsIGxvc3MgaWYgY29udGV4dC5zdWJzZXQgPT0gdGVzdCBhbmQgaHBhcmFtcy5sZWFybmluZ19yYXRlID4gMC4wMDAwMSIsInYiOjF9LCJjb250ZXh0RmlsdGVyIjp7Imdyb3VwQnlDb2xvciI6WyJwYXJhbXMuaHBhcmFtcy5tYXhfayJdLCJncm91cEJ5U3R5bGUiOltdLCJncm91cEJ5Q2hhcnQiOlsibWV0cmljIl0sImdyb3VwQWdhaW5zdCI6eyJjb2xvciI6ZmFsc2UsInN0eWxlIjpmYWxzZSwiY2hhcnQiOmZhbHNlfSwiYWdncmVnYXRlZEFyZWEiOiJzdGRfZGV2IiwiYWdncmVnYXRlZExpbmUiOiJtZWRpYW4iLCJzZWVkIjp7ImNvbG9yIjoxMCwic3R5bGUiOjEwfSwicGVyc2lzdCI6eyJjb2xvciI6ZmFsc2UsInN0eWxlIjpmYWxzZX0sImFnZ3JlZ2F0ZWQiOnRydWV9fQ==).\n\nBelow are the highlight features of the update. Find the full list of changesÂ [here](https://github.com/aimhubio/aim/milestone/3?closed=1).\n\n## System Resource Usage\n\n\n\nNow you can use automatic tracking of your system resources (GPU, CPU, Memory, etc). In order to disable system tracking, just initialize the session withÂ `system_tracking_interval==0`.\n\nOnce you run the training, you will see the following. Here is a demo:\n\n![](https://aimstack.io/wp-content/uploads/2022/02/demo-1.gif \"Aim automatic system resource tracking demo\")\n\nOf course you can alsoÂ [query all those new metrics](https://aimstack.io/wp-admin/post.php?post=706&action=edit)Â in the Explore page and compare, group, aggregate with the rest of the metrics!\n\n## Reverse grouping (â€œagainstâ€ the param)\n\n\n\nAs much as grouping is needed to divide pile of metrics by param values into manageable clusters for comparison, there are cases when the metrics need to be divided by everything BUT one param (yes, I am looking at you seed!). We have called it aÂ Reverse Grouping. Here is how it works:\n\n![](https://aimstack.io/wp-content/uploads/2021/04/reverse-grouping-1024x566.gif \"Aim Reverse grouping demo\")\n\nUse the toggle next to switch between grouping modes.\n\n## Line Chart Smoothing\n\n\n\nNow you can apply smoothing on metrics. Here is how it works:\n\n![](https://aimstack.io/wp-content/uploads/2022/02/metric-smoothing.gif \"Aim metric smoothing\")\n\nThere are two type of smoothing options available:Â `Exponential Moving Average`Â andÂ `Central Moving Average`. Further info ofÂ [how](https://en.wikipedia.org/wiki/Moving_average)Â itâ€™s calculated.\n\n## New aggregation modes\n\n\n\nWe have additionally added two more aggregation modes:Â `standard error`Â andÂ `standard deviation`Â . Here is how it works:\n\n![](https://aimstack.io/wp-content/uploads/2022/02/aggr-modes.gif)\n\n## Learn More\n\n[Aim is on a mission to democratize AI dev tools.](https://github.com/aimhubio/aim#democratizing-ai-dev-tools)\n\nWe have been incredibly lucky to get help and contributions from the amazing Aim community. In fact, Itâ€™s humbling and inspiring.\n\nTry outÂ [Aim](https://github.com/aimhubio/aim), join theÂ [Aim community](https://aimstack.slack.com/?redir=%2Fssb%2Fredirect), share your feedback, open issues for new features, bugs.\n\nAnd donâ€™t forget to leaveÂ [Aim](https://github.com/aimhubio/aim)Â a star on GitHub for support.","html":"<p><a href=\"https://github.com/aimhubio/aim\">Aim</a>Â 2.3.0 is out! Thanks to the community for feedback and support on our journey towards democratizing AI dev tools.</p>\n<p>Check out the updated Aim atÂ <a href=\"http://play.aimstack.io:43900/explore?search=eyJjaGFydCI6eyJzZXR0aW5ncyI6eyJwZXJzaXN0ZW50Ijp7ImRpc3BsYXlPdXRsaWVycyI6ZmFsc2UsInpvb20iOm51bGwsImludGVycG9sYXRlIjp0cnVlLCJpbmRpY2F0b3IiOmZhbHNlLCJ4QWxpZ25tZW50Ijoic3RlcCIsInhTY2FsZSI6MCwieVNjYWxlIjowLCJwb2ludHNDb3VudCI6NTAsInNtb290aGluZ0FsZ29yaXRobSI6ImVtYSIsInNtb290aEZhY3RvciI6MC40NSwiYWdncmVnYXRlZCI6dHJ1ZX19LCJmb2N1c2VkIjp7ImNpcmNsZSI6eyJydW5IYXNoIjpudWxsLCJtZXRyaWNOYW1lIjpudWxsLCJ0cmFjZUNvbnRleHQiOm51bGx9fX0sInNlYXJjaCI6eyJxdWVyeSI6ImJsZXUsIGxvc3MgaWYgY29udGV4dC5zdWJzZXQgPT0gdGVzdCBhbmQgaHBhcmFtcy5sZWFybmluZ19yYXRlID4gMC4wMDAwMSIsInYiOjF9LCJjb250ZXh0RmlsdGVyIjp7Imdyb3VwQnlDb2xvciI6WyJwYXJhbXMuaHBhcmFtcy5tYXhfayJdLCJncm91cEJ5U3R5bGUiOltdLCJncm91cEJ5Q2hhcnQiOlsibWV0cmljIl0sImdyb3VwQWdhaW5zdCI6eyJjb2xvciI6ZmFsc2UsInN0eWxlIjpmYWxzZSwiY2hhcnQiOmZhbHNlfSwiYWdncmVnYXRlZEFyZWEiOiJzdGRfZGV2IiwiYWdncmVnYXRlZExpbmUiOiJtZWRpYW4iLCJzZWVkIjp7ImNvbG9yIjoxMCwic3R5bGUiOjEwfSwicGVyc2lzdCI6eyJjb2xvciI6ZmFsc2UsInN0eWxlIjpmYWxzZX0sImFnZ3JlZ2F0ZWQiOnRydWV9fQ==\">play.aimstack.io</a>.</p>\n<p>Below are the highlight features of the update. Find the full list of changesÂ <a href=\"https://github.com/aimhubio/aim/milestone/3?closed=1\">here</a>.</p>\n<h2>System Resource Usage</h2>\n<p>Now you can use automatic tracking of your system resources (GPU, CPU, Memory, etc). In order to disable system tracking, just initialize the session withÂ <code>system_tracking_interval==0</code>.</p>\n<p>Once you run the training, you will see the following. Here is a demo:</p>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2022/02/demo-1.gif\" alt=\"\" title=\"Aim automatic system resource tracking demo\"></p>\n<p>Of course you can alsoÂ <a href=\"https://aimstack.io/wp-admin/post.php?post=706&#x26;action=edit\">query all those new metrics</a>Â in the Explore page and compare, group, aggregate with the rest of the metrics!</p>\n<h2>Reverse grouping (â€œagainstâ€ the param)</h2>\n<p>As much as grouping is needed to divide pile of metrics by param values into manageable clusters for comparison, there are cases when the metrics need to be divided by everything BUT one param (yes, I am looking at you seed!). We have called it aÂ Reverse Grouping. Here is how it works:</p>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2021/04/reverse-grouping-1024x566.gif\" alt=\"\" title=\"Aim Reverse grouping demo\"></p>\n<p>Use the toggle next to switch between grouping modes.</p>\n<h2>Line Chart Smoothing</h2>\n<p>Now you can apply smoothing on metrics. Here is how it works:</p>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2022/02/metric-smoothing.gif\" alt=\"\" title=\"Aim metric smoothing\"></p>\n<p>There are two type of smoothing options available:Â <code>Exponential Moving Average</code>Â andÂ <code>Central Moving Average</code>. Further info ofÂ <a href=\"https://en.wikipedia.org/wiki/Moving_average\">how</a>Â itâ€™s calculated.</p>\n<h2>New aggregation modes</h2>\n<p>We have additionally added two more aggregation modes:Â <code>standard error</code>Â andÂ <code>standard deviation</code>Â . Here is how it works:</p>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2022/02/aggr-modes.gif\" alt=\"\"></p>\n<h2>Learn More</h2>\n<p><a href=\"https://github.com/aimhubio/aim#democratizing-ai-dev-tools\">Aim is on a mission to democratize AI dev tools.</a></p>\n<p>We have been incredibly lucky to get help and contributions from the amazing Aim community. In fact, Itâ€™s humbling and inspiring.</p>\n<p>Try outÂ <a href=\"https://github.com/aimhubio/aim\">Aim</a>, join theÂ <a href=\"https://aimstack.slack.com/?redir=%2Fssb%2Fredirect\">Aim community</a>, share your feedback, open issues for new features, bugs.</p>\n<p>And donâ€™t forget to leaveÂ <a href=\"https://github.com/aimhubio/aim\">Aim</a>Â a star on GitHub for support.</p>"},"_id":"aim-v2-3-0-â€”-system-resource-usage-and-reverse-grouping.md","_raw":{"sourceFilePath":"aim-v2-3-0-â€”-system-resource-usage-and-reverse-grouping.md","sourceFileName":"aim-v2-3-0-â€”-system-resource-usage-and-reverse-grouping.md","sourceFileDir":".","contentType":"markdown","flattenedPath":"aim-v2-3-0-â€”-system-resource-usage-and-reverse-grouping"},"type":"Post"},{"title":"How to tune hyperparams with fixed seeds using PyTorch Lightning and Aim","date":"2021-03-11T12:46:00.000Z","author":"Gev Soghomonian","description":"What is a random seed and how is it important? The random seed is a number for initializing the pseudorandom number generator. It can have...","slug":"how-to-tune-hyperparams-with-fixed-seeds-using-pytorch-lightning-and-aim","image":"https://aimstack.io/wp-content/uploads/2021/03/pytorch.png","draft":false,"categories":["Tutorials"],"body":{"raw":"## What is a random seed and how is it important?\n\nThe random seed is a number for initializing the pseudorandom number generator. It can have a huge impact on the training results. There are different ways of using the pseudorandom number generator in ML. Here are a few examples:\n\n* Initial weights of the model. When using not fully pre-trained models, one of the most common approaches is to generate the uninitialized weights randomly.\n* Dropout: a common technique in ML that freezes randomly chosen parts of the model during training and recovers them during evaluation.\n* Augmentation: a well-known technique, especially for semi-supervised problems. When the training data is limited, transformations on the available data are used to synthesize new data. Mostly you can randomly choose the transformations and how there application (e.g. change the brightness and its level).\n\nAs you can see, the random seed can have an influence on the result of training in several ways and add a huge variance.Â One thing you do not need when tuning hyper-parameters is variance.\n\nThe purpose of experimenting with hyper-parameters is to find the combination that produces the best results, but when the random seed is not fixed, it is not clear whether the difference was made by the hyperparameter change or the seed change. Therefore, you need to think about a way to train with fixed seed and different hyper-parameters. the need to train with a fixed seed, but different hyper-parameters (comes up)?.\n\nLater in this tutorial, I will show you how to effectively fix a seed for tuning hyper-parameters and how to monitor the results usingÂ [Aim](https://github.com/aimhubio/aim).\n\n## **How to fix the seed in PyTorch Lightning**\n\n\n\nFixing the seed for all imported modules is not as easy as it may seem. The way to fix the random seed for vanilla, non-framework code is to use standard Python`random.seed(seed)`, but it is not enough for PL.\n\nPytorch Lightning, like other frameworks, uses its own generated seeds. There are several ways to fix the seed manually. For PL, we useÂ `pl.seed_everything(seed)`Â . See the docsÂ [here](https://pytorch-lightning.readthedocs.io/en/0.7.6/api/pytorch_lightning.trainer.seed.html).\n\n> Note: in other libraries you would use something like:Â `np.random.seed()`Â orÂ `torch.manual_seed()`Â \n\n## **Implementation**\n\n\n\nFind the full code for this and other tutorialsÂ [here](https://github.com/aimhubio/tutorials/tree/main/fixed-seed).\n\n```\nimport torch\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import CIFAR10\nfrom torchvision.models import resnet18\nfrom torchvision import transforms\nimport pytorch_lightning as pl\nfrom aim.pytorch_lightning import AimLogger\n\nclass ImageClassifierModel(pl.LightningModule):\n\n    def __init__(self, seed, lr, optimizer):\n        super(ImageClassifierModel, self).__init__()\n        pl.seed_everything(seed)\n        # This fixes a seed for all the modules used by pytorch-lightning\n        # Note: using random.seed(seed) is not enough, there are multiple\n        # other seeds like hash seed, seed for numpy etc.\n        self.lr = lr\n        self.optimizer = optimizer\n        self.total_classified = 0\n        self.correctly_classified = 0\n        self.model = resnet18(pretrained = True, progress = True)\n        self.model.fc = torch.nn.Linear(in_features=512, out_features=10, bias=True)\n        # changing the last layer from 1000 out_features to 10 because the model\n        # is pretrained on ImageNet which has 1000 classes but CIFAR10 has 10\n        self.model.to('cuda') # moving the model to cuda\n\n    def train_dataloader(self):\n        # makes the training dataloader\n        train_ds = CIFAR10('.', train = True, transform = transforms.ToTensor(), download = True)\n        train_loader = DataLoader(train_ds, batch_size=32)\n        return train_loader\n        \n    def val_dataloader(self):\n        # makes the validation dataloader\n        val_ds = CIFAR10('.', train = False, transform = transforms.ToTensor(), download = True)\n        val_loader = DataLoader(val_ds, batch_size=32)\n        return val_loader\n\n    def forward(self, x):\n        return self.model.forward(x)\n\n    def training_step(self, batch, batch_nb):\n        x, y = batch\n        y_hat = self.model(x)\n        loss = F.cross_entropy(y_hat, y)\n        # calculating the cross entropy loss on the result\n        self.log('train_loss', loss)\n        # logging the loss with \"train_\" prefix\n        return loss\n\n    def validation_step(self, batch, batch_nb):\n        x, y = batch\n        y_hat = self.model(x)\n        loss = F.cross_entropy(y_hat, y)\n        # calculating the cross entropy loss on the result\n        self.total_classified += y.shape[0]\n        self.correctly_classified += (y_hat.argmax(1) == y).sum().item()\n        # Calculating total and correctly classified images to determine the accuracy later\n        self.log('val_loss', loss) \n        # logging the loss with \"val_\" prefix\n        return loss\n\n    def validation_epoch_end(self, results):\n        accuracy = self.correctly_classified / self.total_classified\n        self.log('val_accuracy', accuracy)\n        # logging accuracy\n        self.total_classified = 0\n        self.correctly_classified = 0\n        return accuracy\n\n    def configure_optimizers(self):\n        # Choose an optimizer and set up a learning rate according to hyperparameters\n        if self.optimizer == 'Adam':\n            return torch.optim.Adam(self.parameters(), lr=self.lr)\n        elif self.optimizer == 'SGD':\n            return torch.optim.SGD(self.parameters(), lr=self.lr)\n        else:\n            raise NotImplementedError\n\nif __name__ == \"__main__\":\n\n    seeds = [47, 881, 123456789]\n    lrs = [0.1, 0.01]\n    optimizers = ['SGD', 'Adam']\n\n    for seed in seeds:\n        for optimizer in optimizers:\n            for lr in lrs:\n                # choosing one set of hyperparaameters from the ones above\n            \n                model = ImageClassifierModel(seed, lr, optimizer)\n                # initializing the model we will train with the chosen hyperparameters\n\n                aim_logger = AimLogger(\n                    experiment='resnet18_classification',\n                    train_metric_prefix='train_',\n                    val_metric_prefix='val_',\n                )\n                aim_logger.log_hyperparams({\n                    'lr': lr,\n                    'optimizer': optimizer,\n                    'seed': seed\n                })\n                # initializing the aim logger and logging the hyperparameters\n\n                trainer = pl.Trainer(\n                    logger=aim_logger,\n                    gpus=1,\n                    max_epochs=5,\n                    progress_bar_refresh_rate=1,\n                    log_every_n_steps=10,\n                    check_val_every_n_epoch=1)\n                # making the pytorch-lightning trainer\n\n                trainer.fit(model)\n                # training the model\n```\n\n\n\n## Analyzing the Training Runs\n\nAfter each set of training runs you need to analyze the results/logs. Use Aim to group the runs by metrics/hyper-parameters (this can be done both on Explore and Dashboard afterÂ [Aim 1.3.5 release](https://aimstack.io/mlops-tools-aim-1-3-5-activity-view-and-x-axis-alignment/)) and have multiple charts of different metrics on the same screen.\n\nDo the following steps to see the different effects of the optimizers\n\n* Go to dashboard, explore by experiment\n* Add loss toÂ `SELECT`Â and divide into subplots by metric\n* Group by experiment to make all metrics of similar color\n* Group by style by optimizer to see different optimizers on loss and accuracy and its effects\n\nHere is how it looks on Aim:\n\n![](https://aimstack.io/wp-content/uploads/2022/02/10.gif)\n\n![](https://aimstack.io/wp-content/uploads/2022/02/11.png)\n\n\n\nFrom the final result it is clear that the SGD (broken lines) optimizer has achieved higher accuracy and lower loss during the training.\n\nIf you apply the same settings to the learning rate, this is the result:\n\n## For the next step to analyze how learning rate affects the experiments, do the following steps:\n\n\n\n* Remove both previous groupings\n* Group by color by learning rate\n\n![](https://aimstack.io/wp-content/uploads/2022/02/12.gif)\n\n![](https://aimstack.io/wp-content/uploads/2022/02/13.png)\n\nAs you can see, the purple lines (lr = 0.01) represent significantly lower loss and higher accuracy.\n\nWe showed that in this case, the choice of the optimizer and learning rate is not dependent on the random seed and it is safe to say that the SGD optimizer with a 0.01 learning rate is the best choice we can make.\n\nOn top of this, if we also add grouping by style by optimizer:\n\n![](https://aimstack.io/wp-content/uploads/2022/02/24.gif)\n\n![](https://aimstack.io/wp-content/uploads/2022/02/25.png)\n\nNow, it is obvious that the the runs with SGD optimizer andÂ `lr=0.01`Â (green, broken lines) are the best choices for all the seeds we have tried.\n\nFixing random seeds is a useful technique that can help step-up your hyper-parameter tuning. This is how to use Aim and PyTorch Lightning to tune hyper-parameters with a fixed seed.\n\n## Learn More\n\n\n\nIf you find Aim useful, support us andÂ [star the project](https://github.com/aimhubio/aim)Â on GitHub. Join theÂ [Aim community](https://aimstack.slack.com/?redir=%2Fssb%2Fredirect)Â and share more about your use-cases and how we can improve Aim to suit them.","html":"<h2>What is a random seed and how is it important?</h2>\n<p>The random seed is a number for initializing the pseudorandom number generator. It can have a huge impact on the training results. There are different ways of using the pseudorandom number generator in ML. Here are a few examples:</p>\n<ul>\n<li>Initial weights of the model. When using not fully pre-trained models, one of the most common approaches is to generate the uninitialized weights randomly.</li>\n<li>Dropout: a common technique in ML that freezes randomly chosen parts of the model during training and recovers them during evaluation.</li>\n<li>Augmentation: a well-known technique, especially for semi-supervised problems. When the training data is limited, transformations on the available data are used to synthesize new data. Mostly you can randomly choose the transformations and how there application (e.g. change the brightness and its level).</li>\n</ul>\n<p>As you can see, the random seed can have an influence on the result of training in several ways and add a huge variance.Â One thing you do not need when tuning hyper-parameters is variance.</p>\n<p>The purpose of experimenting with hyper-parameters is to find the combination that produces the best results, but when the random seed is not fixed, it is not clear whether the difference was made by the hyperparameter change or the seed change. Therefore, you need to think about a way to train with fixed seed and different hyper-parameters. the need to train with a fixed seed, but different hyper-parameters (comes up)?.</p>\n<p>Later in this tutorial, I will show you how to effectively fix a seed for tuning hyper-parameters and how to monitor the results usingÂ <a href=\"https://github.com/aimhubio/aim\">Aim</a>.</p>\n<h2><strong>How to fix the seed in PyTorch Lightning</strong></h2>\n<p>Fixing the seed for all imported modules is not as easy as it may seem. The way to fix the random seed for vanilla, non-framework code is to use standard Python<code>random.seed(seed)</code>, but it is not enough for PL.</p>\n<p>Pytorch Lightning, like other frameworks, uses its own generated seeds. There are several ways to fix the seed manually. For PL, we useÂ <code>pl.seed_everything(seed)</code>Â . See the docsÂ <a href=\"https://pytorch-lightning.readthedocs.io/en/0.7.6/api/pytorch_lightning.trainer.seed.html\">here</a>.</p>\n<blockquote>\n<p>Note: in other libraries you would use something like:Â <code>np.random.seed()</code>Â orÂ <code>torch.manual_seed()</code>Â </p>\n</blockquote>\n<h2><strong>Implementation</strong></h2>\n<p>Find the full code for this and other tutorialsÂ <a href=\"https://github.com/aimhubio/tutorials/tree/main/fixed-seed\">here</a>.</p>\n<pre><code>import torch\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import CIFAR10\nfrom torchvision.models import resnet18\nfrom torchvision import transforms\nimport pytorch_lightning as pl\nfrom aim.pytorch_lightning import AimLogger\n\nclass ImageClassifierModel(pl.LightningModule):\n\n    def __init__(self, seed, lr, optimizer):\n        super(ImageClassifierModel, self).__init__()\n        pl.seed_everything(seed)\n        # This fixes a seed for all the modules used by pytorch-lightning\n        # Note: using random.seed(seed) is not enough, there are multiple\n        # other seeds like hash seed, seed for numpy etc.\n        self.lr = lr\n        self.optimizer = optimizer\n        self.total_classified = 0\n        self.correctly_classified = 0\n        self.model = resnet18(pretrained = True, progress = True)\n        self.model.fc = torch.nn.Linear(in_features=512, out_features=10, bias=True)\n        # changing the last layer from 1000 out_features to 10 because the model\n        # is pretrained on ImageNet which has 1000 classes but CIFAR10 has 10\n        self.model.to('cuda') # moving the model to cuda\n\n    def train_dataloader(self):\n        # makes the training dataloader\n        train_ds = CIFAR10('.', train = True, transform = transforms.ToTensor(), download = True)\n        train_loader = DataLoader(train_ds, batch_size=32)\n        return train_loader\n        \n    def val_dataloader(self):\n        # makes the validation dataloader\n        val_ds = CIFAR10('.', train = False, transform = transforms.ToTensor(), download = True)\n        val_loader = DataLoader(val_ds, batch_size=32)\n        return val_loader\n\n    def forward(self, x):\n        return self.model.forward(x)\n\n    def training_step(self, batch, batch_nb):\n        x, y = batch\n        y_hat = self.model(x)\n        loss = F.cross_entropy(y_hat, y)\n        # calculating the cross entropy loss on the result\n        self.log('train_loss', loss)\n        # logging the loss with \"train_\" prefix\n        return loss\n\n    def validation_step(self, batch, batch_nb):\n        x, y = batch\n        y_hat = self.model(x)\n        loss = F.cross_entropy(y_hat, y)\n        # calculating the cross entropy loss on the result\n        self.total_classified += y.shape[0]\n        self.correctly_classified += (y_hat.argmax(1) == y).sum().item()\n        # Calculating total and correctly classified images to determine the accuracy later\n        self.log('val_loss', loss) \n        # logging the loss with \"val_\" prefix\n        return loss\n\n    def validation_epoch_end(self, results):\n        accuracy = self.correctly_classified / self.total_classified\n        self.log('val_accuracy', accuracy)\n        # logging accuracy\n        self.total_classified = 0\n        self.correctly_classified = 0\n        return accuracy\n\n    def configure_optimizers(self):\n        # Choose an optimizer and set up a learning rate according to hyperparameters\n        if self.optimizer == 'Adam':\n            return torch.optim.Adam(self.parameters(), lr=self.lr)\n        elif self.optimizer == 'SGD':\n            return torch.optim.SGD(self.parameters(), lr=self.lr)\n        else:\n            raise NotImplementedError\n\nif __name__ == \"__main__\":\n\n    seeds = [47, 881, 123456789]\n    lrs = [0.1, 0.01]\n    optimizers = ['SGD', 'Adam']\n\n    for seed in seeds:\n        for optimizer in optimizers:\n            for lr in lrs:\n                # choosing one set of hyperparaameters from the ones above\n            \n                model = ImageClassifierModel(seed, lr, optimizer)\n                # initializing the model we will train with the chosen hyperparameters\n\n                aim_logger = AimLogger(\n                    experiment='resnet18_classification',\n                    train_metric_prefix='train_',\n                    val_metric_prefix='val_',\n                )\n                aim_logger.log_hyperparams({\n                    'lr': lr,\n                    'optimizer': optimizer,\n                    'seed': seed\n                })\n                # initializing the aim logger and logging the hyperparameters\n\n                trainer = pl.Trainer(\n                    logger=aim_logger,\n                    gpus=1,\n                    max_epochs=5,\n                    progress_bar_refresh_rate=1,\n                    log_every_n_steps=10,\n                    check_val_every_n_epoch=1)\n                # making the pytorch-lightning trainer\n\n                trainer.fit(model)\n                # training the model\n</code></pre>\n<h2>Analyzing the Training Runs</h2>\n<p>After each set of training runs you need to analyze the results/logs. Use Aim to group the runs by metrics/hyper-parameters (this can be done both on Explore and Dashboard afterÂ <a href=\"https://aimstack.io/mlops-tools-aim-1-3-5-activity-view-and-x-axis-alignment/\">Aim 1.3.5 release</a>) and have multiple charts of different metrics on the same screen.</p>\n<p>Do the following steps to see the different effects of the optimizers</p>\n<ul>\n<li>Go to dashboard, explore by experiment</li>\n<li>Add loss toÂ <code>SELECT</code>Â and divide into subplots by metric</li>\n<li>Group by experiment to make all metrics of similar color</li>\n<li>Group by style by optimizer to see different optimizers on loss and accuracy and its effects</li>\n</ul>\n<p>Here is how it looks on Aim:</p>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2022/02/10.gif\" alt=\"\"></p>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2022/02/11.png\" alt=\"\"></p>\n<p>From the final result it is clear that the SGD (broken lines) optimizer has achieved higher accuracy and lower loss during the training.</p>\n<p>If you apply the same settings to the learning rate, this is the result:</p>\n<h2>For the next step to analyze how learning rate affects the experiments, do the following steps:</h2>\n<ul>\n<li>Remove both previous groupings</li>\n<li>Group by color by learning rate</li>\n</ul>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2022/02/12.gif\" alt=\"\"></p>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2022/02/13.png\" alt=\"\"></p>\n<p>As you can see, the purple lines (lr = 0.01) represent significantly lower loss and higher accuracy.</p>\n<p>We showed that in this case, the choice of the optimizer and learning rate is not dependent on the random seed and it is safe to say that the SGD optimizer with a 0.01 learning rate is the best choice we can make.</p>\n<p>On top of this, if we also add grouping by style by optimizer:</p>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2022/02/24.gif\" alt=\"\"></p>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2022/02/25.png\" alt=\"\"></p>\n<p>Now, it is obvious that the the runs with SGD optimizer andÂ <code>lr=0.01</code>Â (green, broken lines) are the best choices for all the seeds we have tried.</p>\n<p>Fixing random seeds is a useful technique that can help step-up your hyper-parameter tuning. This is how to use Aim and PyTorch Lightning to tune hyper-parameters with a fixed seed.</p>\n<h2>Learn More</h2>\n<p>If you find Aim useful, support us andÂ <a href=\"https://github.com/aimhubio/aim\">star the project</a>Â on GitHub. Join theÂ <a href=\"https://aimstack.slack.com/?redir=%2Fssb%2Fredirect\">Aim community</a>Â and share more about your use-cases and how we can improve Aim to suit them.</p>"},"_id":"how-to-tune-hyperparams-with-fixed-seeds-using-pytorch-lightning-and-aim.md","_raw":{"sourceFilePath":"how-to-tune-hyperparams-with-fixed-seeds-using-pytorch-lightning-and-aim.md","sourceFileName":"how-to-tune-hyperparams-with-fixed-seeds-using-pytorch-lightning-and-aim.md","sourceFileDir":".","contentType":"markdown","flattenedPath":"how-to-tune-hyperparams-with-fixed-seeds-using-pytorch-lightning-and-aim"},"type":"Post"}]},"__N_SSG":true}