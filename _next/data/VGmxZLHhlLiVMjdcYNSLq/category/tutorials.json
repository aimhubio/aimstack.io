{"pageProps":{"posts":[{"title":"Aim basics: using context and subplots to compare validation and test metrics","date":"2021-02-16T12:18:06.528Z","author":"Gev Soghomonian","description":"Validation and test metrics comparison is a crucial step in ML experiments. ML researchers divide datasets into three subsets — train, validation and test so they can test their model","slug":"aim-basics-using-context-and-subplots-to-compare-validation-and-test-metrics","image":"/images/dynamic/1.gif","draft":false,"categories":["Tutorials"],"body":{"raw":"Researchers divide datasets into three subsets — train, validation and test so they can test their model performance at different levels.\n\nThe model is trained on the train subset and subsequent metrics are collected to evaluate how well the training is going. Loss, accuracy and other metrics are computed.\n\nThe validation and test sets are used to test the model on additional unseen data to verify how well it generalise.\n\nModels are usually ran on validation subset after each epoch.\\\nOnce the training is done, models are tested on the test subset to verify the final performance and generalisation.\n\nThere is a need to collect and effectively compare all these metrics.\n\nHere is how to do that on [Aim](https://github.com/aimhubio/aim)\n\n# Using context to track for different subsets?\n\nUse the [aim.track](https://github.com/aimhubio/aim#track) context arguments to pass additional information about the metrics. All context parameters can be used to query, group and do other operations on top of the metrics.\n\n![](<script src=\"https://gist.github.com/SGevorg/e08524b3538d3f71d14bf1857a7bc6e9.js\"></script> \"Here is how it looks like on the code\")\n\nOnce the training is ran, execute `aim up` in your terminal and start the Aim UI.\n\n# Using subplots to compare test, val loss and bleu metrics\n\n> **\\*Note:** The bleu metric is used here instead of accuracy as we are looking at Neural Machine Translation experiments. But this works with every other metric too.*\n\nLet’s go step-by-step on how to break down lots of experiments using subplots.\n\n**Step 1.** Explore the runs, the context table, play with the query language.\n\n![](/images/dynamic/1_tfc_fuc-axk07z3-a7jsmg.gif \"Explore the training runs\")\n\n**Step 2.** Add the `bleu` metric to the Select input — query both metrics at the same time. Divide into subplots by metric.\n\n![](https://miro.medium.com/max/1400/1*BQK8qGoG3v4KMpssvzC0hw.gif \"Divide into subplots by metric\")\n\n**Step 3.** Search by `context.subset` to show both `test` and `val` `loss` and `bleu` metrics. Divide into subplots further by `context.subset` too so Aim UI shows `test` and `val` metrics on different subplots for better comparison.\n\n![](https://miro.medium.com/max/1400/1*fSm2PyNwbcBaAoZceq6Qsw.gif \"Divide into subplots by context / subset\")\n\nNot it’s easy and straightforward to simultaneously compare both 4 metrics and find the best version of the model.\n\n# Summary\n\nHere is a full summary video on how to do it on the UI.\n\n![](https://www.youtube.com/watch?v=DGI8S7SUfEk)\n\n# Learn More\n\nIf you find Aim useful, support us and [star the project](https://github.com/aimhubio/aim) on GitHub. Join the [Aim community](https://slack.aimstack.io/) and share more about your use-cases and how we can improve Aim to suit them.","html":"<p>Researchers divide datasets into three subsets — train, validation and test so they can test their model performance at different levels.</p>\n<p>The model is trained on the train subset and subsequent metrics are collected to evaluate how well the training is going. Loss, accuracy and other metrics are computed.</p>\n<p>The validation and test sets are used to test the model on additional unseen data to verify how well it generalise.</p>\n<p>Models are usually ran on validation subset after each epoch.<br>\nOnce the training is done, models are tested on the test subset to verify the final performance and generalisation.</p>\n<p>There is a need to collect and effectively compare all these metrics.</p>\n<p>Here is how to do that on <a href=\"https://github.com/aimhubio/aim\">Aim</a></p>\n<h1>Using context to track for different subsets?</h1>\n<p>Use the <a href=\"https://github.com/aimhubio/aim#track\">aim.track</a> context arguments to pass additional information about the metrics. All context parameters can be used to query, group and do other operations on top of the metrics.</p>\n<p>![]( \"Here is how it looks like on the code\")</p>\n<p>Once the training is ran, execute <code>aim up</code> in your terminal and start the Aim UI.</p>\n<h1>Using subplots to compare test, val loss and bleu metrics</h1>\n<blockquote>\n<p><strong>*Note:</strong> The bleu metric is used here instead of accuracy as we are looking at Neural Machine Translation experiments. But this works with every other metric too.*</p>\n</blockquote>\n<p>Let’s go step-by-step on how to break down lots of experiments using subplots.</p>\n<p><strong>Step 1.</strong> Explore the runs, the context table, play with the query language.</p>\n<p><img src=\"/images/dynamic/1_tfc_fuc-axk07z3-a7jsmg.gif\" alt=\"\" title=\"Explore the training runs\"></p>\n<p><strong>Step 2.</strong> Add the <code>bleu</code> metric to the Select input — query both metrics at the same time. Divide into subplots by metric.</p>\n<p><img src=\"https://miro.medium.com/max/1400/1*BQK8qGoG3v4KMpssvzC0hw.gif\" alt=\"\" title=\"Divide into subplots by metric\"></p>\n<p><strong>Step 3.</strong> Search by <code>context.subset</code> to show both <code>test</code> and <code>val</code> <code>loss</code> and <code>bleu</code> metrics. Divide into subplots further by <code>context.subset</code> too so Aim UI shows <code>test</code> and <code>val</code> metrics on different subplots for better comparison.</p>\n<p><img src=\"https://miro.medium.com/max/1400/1*fSm2PyNwbcBaAoZceq6Qsw.gif\" alt=\"\" title=\"Divide into subplots by context / subset\"></p>\n<p>Not it’s easy and straightforward to simultaneously compare both 4 metrics and find the best version of the model.</p>\n<h1>Summary</h1>\n<p>Here is a full summary video on how to do it on the UI.</p>\n<p><img src=\"https://www.youtube.com/watch?v=DGI8S7SUfEk\" alt=\"\"></p>\n<h1>Learn More</h1>\n<p>If you find Aim useful, support us and <a href=\"https://github.com/aimhubio/aim\">star the project</a> on GitHub. Join the <a href=\"https://slack.aimstack.io/\">Aim community</a> and share more about your use-cases and how we can improve Aim to suit them.</p>"},"_id":"aim-basics-using-context-and-subplots-to-compare-validation-and-test-metrics.md","_raw":{"sourceFilePath":"aim-basics-using-context-and-subplots-to-compare-validation-and-test-metrics.md","sourceFileName":"aim-basics-using-context-and-subplots-to-compare-validation-and-test-metrics.md","sourceFileDir":".","contentType":"markdown","flattenedPath":"aim-basics-using-context-and-subplots-to-compare-validation-and-test-metrics"},"type":"Post"},{"title":"An end-to-end example of Aim logger used with XGBoost library","date":"2021-05-17T14:12:33.016Z","author":"Khazhak Galstyan","description":" Thanks to the community for feedback and support on our journey towards democratizing MLOps tools. Check out […]  Read More 122  0 XGBoost  Tutorials An end-to-end example of Aim logger used… What is Aim? Aim is an open-source tool for AI experiment comparison. With more resources and complex models, more experiments are ran than ever. ","slug":"an-end-to-end-example-of-aim-logger-used-with-xgboost-library","image":"https://aimstack.io/wp-content/uploads/2022/02/xgboost.png","draft":false,"categories":["Tutorials"],"body":{"raw":"## What is Aim?\n\n[Aim](https://github.com/aimhubio/aim) is an open-source tool for AI experiment comparison. With more resources and complex models, more experiments are ran than ever. You can indeed use Aim to deeply inspect thousands of hyperparameter-sensitive training runs.\n\n## What is XGBoost?\n\n[XGBoost](https://github.com/dmlc/xgboost) is an optimized gradient boosting library with highly  *efficient*,  *flexible,*  and  *portable* design. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solves many data science problems in a fast and accurate way. Subsequently, the same code runs on major distributed environment (Kubernetes, Hadoop, SGE, MPI, Dask) and can solve problems beyond billions of examples.\n\n## How to use Aim with XGBoost?\n\nCheck out end-to-end [Aim integration](https://aimstack.io/aim-2-4-0-xgboost-integration-and-confidence-interval-aggregation/) examples with multiple frameworks [here](https://github.com/aimhubio/aim/tree/main/examples). In this tutorial, we are going to show how to integrate Aim and use AimCallback in your XGBoost code.\n\n```\n# You should download and extract the data beforehand. Simply by doing this: \n# wget https://archive.ics.uci.edu/ml/machine-learning-databases/dermatology/dermatology.data\n\nfrom __future__ import division\n\nimport numpy as np\nimport xgboost as xgb\nfrom aim.xgboost import AimCallback\n\n# label need to be 0 to num_class -1\ndata = np.loadtxt('./dermatology.data', delimiter=',',\n        converters={33: lambda x:int(x == '?'), 34: lambda x:int(x) - 1})\nsz = data.shape\n\ntrain = data[:int(sz[0] * 0.7), :]\ntest = data[int(sz[0] * 0.7):, :]\n\ntrain_X = train[:, :33]\ntrain_Y = train[:, 34]\n\ntest_X = test[:, :33]\ntest_Y = test[:, 34]\nprint(len(train_X))\n\nxg_train = xgb.DMatrix(train_X, label=train_Y)\nxg_test = xgb.DMatrix(test_X, label=test_Y)\n# setup parameters for xgboost\nparam = {}\n# use softmax multi-class classification\nparam['objective'] = 'multi:softmax'\n# scale weight of positive examples\nparam['eta'] = 0.1\nparam['max_depth'] = 6\nparam['nthread'] = 4\nparam['num_class'] = 6\n\nwatchlist = [(xg_train, 'train'), (xg_test, 'test')]\nnum_round = 50\nbst = xgb.train(param, xg_train, num_round, watchlist)\n# get prediction\npred = bst.predict(xg_test)\nerror_rate = np.sum(pred != test_Y) / test_Y.shape[0]\nprint('Test error using softmax = {}'.format(error_rate))\n\n# do the same thing again, but output probabilities\nparam['objective'] = 'multi:softprob'\nbst = xgb.train(param, xg_train, num_round, watchlist, \n                callbacks=[AimCallback(repo='.', experiment='xgboost_test')])\n# Note: this convention has been changed since xgboost-unity\n# get prediction, this is in 1D array, need reshape to (ndata, nclass)\npred_prob = bst.predict(xg_test).reshape(test_Y.shape[0], 6)\npred_label = np.argmax(pred_prob, axis=1)\nerror_rate = np.sum(pred_label != test_Y) / test_Y.shape[0]\nprint('Test error using softprob = {}'.format(error_rate))\n```\n\nAs you can see on line 49, AimCallback is imported from `aim.xgboost` and passed to `xgb.train` as one of the callbacks. Aim session can open and close by the AimCallback and the metrics and hparamsstore by XGBoost. In addition to that, thesystem measures pass to Aim as well.\n\n## What it looks like?\n\nAfter you run the experiment and the `aim up` command in the `aim_logs`directory, Aim UI will be running. When first opened, the dashboard page will come up.\n\n![](https://aimstack.io/wp-content/uploads/2021/05/dashboard.png \"Aim UI dashboard page\")\n\nTo explore the run, we should:\n\n* Choose the `xgboost_test`experiment.\n* Select the metrics to explore.\n* Divide into charts by metrics.\n\nFor example, the gif below illustrates the steps above.\n\n![](https://aimstack.io/wp-content/uploads/2021/05/1.gif)\n\n\\\n So this is what the final result looks like.\n\n![](https://aimstack.io/wp-content/uploads/2021/05/2.png)\n\nIn short, we can easily analyze the runs and the system usage.\n\n## Learn More\n\n[Aim is on a mission to democratize AI dev tools.](https://github.com/aimhubio/aim#democratizing-ai-dev-tools)\n\nIf you find Aim useful, support us and star [the project](https://github.com/aimhubio/aim) on GitHub. Also, join the [Aim community](https://aimstack.slack.com/ssb/redirect) and share more about your use-cases and how we can improve Aim to suit them.","html":"<h2>What is Aim?</h2>\n<p><a href=\"https://github.com/aimhubio/aim\">Aim</a> is an open-source tool for AI experiment comparison. With more resources and complex models, more experiments are ran than ever. You can indeed use Aim to deeply inspect thousands of hyperparameter-sensitive training runs.</p>\n<h2>What is XGBoost?</h2>\n<p><a href=\"https://github.com/dmlc/xgboost\">XGBoost</a> is an optimized gradient boosting library with highly  <em>efficient</em>,  <em>flexible,</em>  and  <em>portable</em> design. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solves many data science problems in a fast and accurate way. Subsequently, the same code runs on major distributed environment (Kubernetes, Hadoop, SGE, MPI, Dask) and can solve problems beyond billions of examples.</p>\n<h2>How to use Aim with XGBoost?</h2>\n<p>Check out end-to-end <a href=\"https://aimstack.io/aim-2-4-0-xgboost-integration-and-confidence-interval-aggregation/\">Aim integration</a> examples with multiple frameworks <a href=\"https://github.com/aimhubio/aim/tree/main/examples\">here</a>. In this tutorial, we are going to show how to integrate Aim and use AimCallback in your XGBoost code.</p>\n<pre><code># You should download and extract the data beforehand. Simply by doing this: \n# wget https://archive.ics.uci.edu/ml/machine-learning-databases/dermatology/dermatology.data\n\nfrom __future__ import division\n\nimport numpy as np\nimport xgboost as xgb\nfrom aim.xgboost import AimCallback\n\n# label need to be 0 to num_class -1\ndata = np.loadtxt('./dermatology.data', delimiter=',',\n        converters={33: lambda x:int(x == '?'), 34: lambda x:int(x) - 1})\nsz = data.shape\n\ntrain = data[:int(sz[0] * 0.7), :]\ntest = data[int(sz[0] * 0.7):, :]\n\ntrain_X = train[:, :33]\ntrain_Y = train[:, 34]\n\ntest_X = test[:, :33]\ntest_Y = test[:, 34]\nprint(len(train_X))\n\nxg_train = xgb.DMatrix(train_X, label=train_Y)\nxg_test = xgb.DMatrix(test_X, label=test_Y)\n# setup parameters for xgboost\nparam = {}\n# use softmax multi-class classification\nparam['objective'] = 'multi:softmax'\n# scale weight of positive examples\nparam['eta'] = 0.1\nparam['max_depth'] = 6\nparam['nthread'] = 4\nparam['num_class'] = 6\n\nwatchlist = [(xg_train, 'train'), (xg_test, 'test')]\nnum_round = 50\nbst = xgb.train(param, xg_train, num_round, watchlist)\n# get prediction\npred = bst.predict(xg_test)\nerror_rate = np.sum(pred != test_Y) / test_Y.shape[0]\nprint('Test error using softmax = {}'.format(error_rate))\n\n# do the same thing again, but output probabilities\nparam['objective'] = 'multi:softprob'\nbst = xgb.train(param, xg_train, num_round, watchlist, \n                callbacks=[AimCallback(repo='.', experiment='xgboost_test')])\n# Note: this convention has been changed since xgboost-unity\n# get prediction, this is in 1D array, need reshape to (ndata, nclass)\npred_prob = bst.predict(xg_test).reshape(test_Y.shape[0], 6)\npred_label = np.argmax(pred_prob, axis=1)\nerror_rate = np.sum(pred_label != test_Y) / test_Y.shape[0]\nprint('Test error using softprob = {}'.format(error_rate))\n</code></pre>\n<p>As you can see on line 49, AimCallback is imported from <code>aim.xgboost</code> and passed to <code>xgb.train</code> as one of the callbacks. Aim session can open and close by the AimCallback and the metrics and hparamsstore by XGBoost. In addition to that, thesystem measures pass to Aim as well.</p>\n<h2>What it looks like?</h2>\n<p>After you run the experiment and the <code>aim up</code> command in the <code>aim_logs</code>directory, Aim UI will be running. When first opened, the dashboard page will come up.</p>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2021/05/dashboard.png\" alt=\"\" title=\"Aim UI dashboard page\"></p>\n<p>To explore the run, we should:</p>\n<ul>\n<li>Choose the <code>xgboost_test</code>experiment.</li>\n<li>Select the metrics to explore.</li>\n<li>Divide into charts by metrics.</li>\n</ul>\n<p>For example, the gif below illustrates the steps above.</p>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2021/05/1.gif\" alt=\"\"></p>\n<p><br>\nSo this is what the final result looks like.</p>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2021/05/2.png\" alt=\"\"></p>\n<p>In short, we can easily analyze the runs and the system usage.</p>\n<h2>Learn More</h2>\n<p><a href=\"https://github.com/aimhubio/aim#democratizing-ai-dev-tools\">Aim is on a mission to democratize AI dev tools.</a></p>\n<p>If you find Aim useful, support us and star <a href=\"https://github.com/aimhubio/aim\">the project</a> on GitHub. Also, join the <a href=\"https://aimstack.slack.com/ssb/redirect\">Aim community</a> and share more about your use-cases and how we can improve Aim to suit them.</p>"},"_id":"an-end-to-end-example-of-aim-logger-used-with-xgboost-library.md","_raw":{"sourceFilePath":"an-end-to-end-example-of-aim-logger-used-with-xgboost-library.md","sourceFileName":"an-end-to-end-example-of-aim-logger-used-with-xgboost-library.md","sourceFileDir":".","contentType":"markdown","flattenedPath":"an-end-to-end-example-of-aim-logger-used-with-xgboost-library"},"type":"Post"},{"title":"How to tune hyperparams with fixed seeds using PyTorch Lightning and Aim","date":"2021-03-11T12:46:00.000Z","author":"Gev Soghomonian","description":"What is a random seed and how is it important? The random seed is a number for initializing the pseudorandom number generator. It can have...","slug":"how-to-tune-hyperparams-with-fixed-seeds-using-pytorch-lightning-and-aim","image":"https://aimstack.io/wp-content/uploads/2021/03/pytorch.png","draft":false,"categories":["Tutorials"],"body":{"raw":"## What is a random seed and how is it important?\n\nThe random seed is a number for initializing the pseudorandom number generator. It can have a huge impact on the training results. There are different ways of using the pseudorandom number generator in ML. Here are a few examples:\n\n* Initial weights of the model. When using not fully pre-trained models, one of the most common approaches is to generate the uninitialized weights randomly.\n* Dropout: a common technique in ML that freezes randomly chosen parts of the model during training and recovers them during evaluation.\n* Augmentation: a well-known technique, especially for semi-supervised problems. When the training data is limited, transformations on the available data are used to synthesize new data. Mostly you can randomly choose the transformations and how there application (e.g. change the brightness and its level).\n\nAs you can see, the random seed can have an influence on the result of training in several ways and add a huge variance. One thing you do not need when tuning hyper-parameters is variance.\n\nThe purpose of experimenting with hyper-parameters is to find the combination that produces the best results, but when the random seed is not fixed, it is not clear whether the difference was made by the hyperparameter change or the seed change. Therefore, you need to think about a way to train with fixed seed and different hyper-parameters. the need to train with a fixed seed, but different hyper-parameters (comes up)?.\n\nLater in this tutorial, I will show you how to effectively fix a seed for tuning hyper-parameters and how to monitor the results using [Aim](https://github.com/aimhubio/aim).\n\n## **How to fix the seed in PyTorch Lightning**\n\n\n\nFixing the seed for all imported modules is not as easy as it may seem. The way to fix the random seed for vanilla, non-framework code is to use standard Python`random.seed(seed)`, but it is not enough for PL.\n\nPytorch Lightning, like other frameworks, uses its own generated seeds. There are several ways to fix the seed manually. For PL, we use `pl.seed_everything(seed)` . See the docs [here](https://pytorch-lightning.readthedocs.io/en/0.7.6/api/pytorch_lightning.trainer.seed.html).\n\n> Note: in other libraries you would use something like: `np.random.seed()` or `torch.manual_seed()` \n\n## **Implementation**\n\n\n\nFind the full code for this and other tutorials [here](https://github.com/aimhubio/tutorials/tree/main/fixed-seed).\n\n```\nimport torch\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import CIFAR10\nfrom torchvision.models import resnet18\nfrom torchvision import transforms\nimport pytorch_lightning as pl\nfrom aim.pytorch_lightning import AimLogger\n\nclass ImageClassifierModel(pl.LightningModule):\n\n    def __init__(self, seed, lr, optimizer):\n        super(ImageClassifierModel, self).__init__()\n        pl.seed_everything(seed)\n        # This fixes a seed for all the modules used by pytorch-lightning\n        # Note: using random.seed(seed) is not enough, there are multiple\n        # other seeds like hash seed, seed for numpy etc.\n        self.lr = lr\n        self.optimizer = optimizer\n        self.total_classified = 0\n        self.correctly_classified = 0\n        self.model = resnet18(pretrained = True, progress = True)\n        self.model.fc = torch.nn.Linear(in_features=512, out_features=10, bias=True)\n        # changing the last layer from 1000 out_features to 10 because the model\n        # is pretrained on ImageNet which has 1000 classes but CIFAR10 has 10\n        self.model.to('cuda') # moving the model to cuda\n\n    def train_dataloader(self):\n        # makes the training dataloader\n        train_ds = CIFAR10('.', train = True, transform = transforms.ToTensor(), download = True)\n        train_loader = DataLoader(train_ds, batch_size=32)\n        return train_loader\n        \n    def val_dataloader(self):\n        # makes the validation dataloader\n        val_ds = CIFAR10('.', train = False, transform = transforms.ToTensor(), download = True)\n        val_loader = DataLoader(val_ds, batch_size=32)\n        return val_loader\n\n    def forward(self, x):\n        return self.model.forward(x)\n\n    def training_step(self, batch, batch_nb):\n        x, y = batch\n        y_hat = self.model(x)\n        loss = F.cross_entropy(y_hat, y)\n        # calculating the cross entropy loss on the result\n        self.log('train_loss', loss)\n        # logging the loss with \"train_\" prefix\n        return loss\n\n    def validation_step(self, batch, batch_nb):\n        x, y = batch\n        y_hat = self.model(x)\n        loss = F.cross_entropy(y_hat, y)\n        # calculating the cross entropy loss on the result\n        self.total_classified += y.shape[0]\n        self.correctly_classified += (y_hat.argmax(1) == y).sum().item()\n        # Calculating total and correctly classified images to determine the accuracy later\n        self.log('val_loss', loss) \n        # logging the loss with \"val_\" prefix\n        return loss\n\n    def validation_epoch_end(self, results):\n        accuracy = self.correctly_classified / self.total_classified\n        self.log('val_accuracy', accuracy)\n        # logging accuracy\n        self.total_classified = 0\n        self.correctly_classified = 0\n        return accuracy\n\n    def configure_optimizers(self):\n        # Choose an optimizer and set up a learning rate according to hyperparameters\n        if self.optimizer == 'Adam':\n            return torch.optim.Adam(self.parameters(), lr=self.lr)\n        elif self.optimizer == 'SGD':\n            return torch.optim.SGD(self.parameters(), lr=self.lr)\n        else:\n            raise NotImplementedError\n\nif __name__ == \"__main__\":\n\n    seeds = [47, 881, 123456789]\n    lrs = [0.1, 0.01]\n    optimizers = ['SGD', 'Adam']\n\n    for seed in seeds:\n        for optimizer in optimizers:\n            for lr in lrs:\n                # choosing one set of hyperparaameters from the ones above\n            \n                model = ImageClassifierModel(seed, lr, optimizer)\n                # initializing the model we will train with the chosen hyperparameters\n\n                aim_logger = AimLogger(\n                    experiment='resnet18_classification',\n                    train_metric_prefix='train_',\n                    val_metric_prefix='val_',\n                )\n                aim_logger.log_hyperparams({\n                    'lr': lr,\n                    'optimizer': optimizer,\n                    'seed': seed\n                })\n                # initializing the aim logger and logging the hyperparameters\n\n                trainer = pl.Trainer(\n                    logger=aim_logger,\n                    gpus=1,\n                    max_epochs=5,\n                    progress_bar_refresh_rate=1,\n                    log_every_n_steps=10,\n                    check_val_every_n_epoch=1)\n                # making the pytorch-lightning trainer\n\n                trainer.fit(model)\n                # training the model\n```\n\n\n\n## Analyzing the Training Runs\n\nAfter each set of training runs you need to analyze the results/logs. Use Aim to group the runs by metrics/hyper-parameters (this can be done both on Explore and Dashboard after [Aim 1.3.5 release](https://aimstack.io/mlops-tools-aim-1-3-5-activity-view-and-x-axis-alignment/)) and have multiple charts of different metrics on the same screen.\n\nDo the following steps to see the different effects of the optimizers\n\n* Go to dashboard, explore by experiment\n* Add loss to `SELECT` and divide into subplots by metric\n* Group by experiment to make all metrics of similar color\n* Group by style by optimizer to see different optimizers on loss and accuracy and its effects\n\nHere is how it looks on Aim:\n\n![](https://aimstack.io/wp-content/uploads/2022/02/10.gif)\n\n![](https://aimstack.io/wp-content/uploads/2022/02/11.png)\n\n\n\nFrom the final result it is clear that the SGD (broken lines) optimizer has achieved higher accuracy and lower loss during the training.\n\nIf you apply the same settings to the learning rate, this is the result:\n\n## For the next step to analyze how learning rate affects the experiments, do the following steps:\n\n\n\n* Remove both previous groupings\n* Group by color by learning rate\n\n![](https://aimstack.io/wp-content/uploads/2022/02/12.gif)\n\n![](https://aimstack.io/wp-content/uploads/2022/02/13.png)\n\nAs you can see, the purple lines (lr = 0.01) represent significantly lower loss and higher accuracy.\n\nWe showed that in this case, the choice of the optimizer and learning rate is not dependent on the random seed and it is safe to say that the SGD optimizer with a 0.01 learning rate is the best choice we can make.\n\nOn top of this, if we also add grouping by style by optimizer:\n\n![](https://aimstack.io/wp-content/uploads/2022/02/24.gif)\n\n![](https://aimstack.io/wp-content/uploads/2022/02/25.png)\n\nNow, it is obvious that the the runs with SGD optimizer and `lr=0.01` (green, broken lines) are the best choices for all the seeds we have tried.\n\nFixing random seeds is a useful technique that can help step-up your hyper-parameter tuning. This is how to use Aim and PyTorch Lightning to tune hyper-parameters with a fixed seed.\n\n## Learn More\n\n\n\nIf you find Aim useful, support us and [star the project](https://github.com/aimhubio/aim) on GitHub. Join the [Aim community](https://aimstack.slack.com/?redir=%2Fssb%2Fredirect) and share more about your use-cases and how we can improve Aim to suit them.","html":"<h2>What is a random seed and how is it important?</h2>\n<p>The random seed is a number for initializing the pseudorandom number generator. It can have a huge impact on the training results. There are different ways of using the pseudorandom number generator in ML. Here are a few examples:</p>\n<ul>\n<li>Initial weights of the model. When using not fully pre-trained models, one of the most common approaches is to generate the uninitialized weights randomly.</li>\n<li>Dropout: a common technique in ML that freezes randomly chosen parts of the model during training and recovers them during evaluation.</li>\n<li>Augmentation: a well-known technique, especially for semi-supervised problems. When the training data is limited, transformations on the available data are used to synthesize new data. Mostly you can randomly choose the transformations and how there application (e.g. change the brightness and its level).</li>\n</ul>\n<p>As you can see, the random seed can have an influence on the result of training in several ways and add a huge variance. One thing you do not need when tuning hyper-parameters is variance.</p>\n<p>The purpose of experimenting with hyper-parameters is to find the combination that produces the best results, but when the random seed is not fixed, it is not clear whether the difference was made by the hyperparameter change or the seed change. Therefore, you need to think about a way to train with fixed seed and different hyper-parameters. the need to train with a fixed seed, but different hyper-parameters (comes up)?.</p>\n<p>Later in this tutorial, I will show you how to effectively fix a seed for tuning hyper-parameters and how to monitor the results using <a href=\"https://github.com/aimhubio/aim\">Aim</a>.</p>\n<h2><strong>How to fix the seed in PyTorch Lightning</strong></h2>\n<p>Fixing the seed for all imported modules is not as easy as it may seem. The way to fix the random seed for vanilla, non-framework code is to use standard Python<code>random.seed(seed)</code>, but it is not enough for PL.</p>\n<p>Pytorch Lightning, like other frameworks, uses its own generated seeds. There are several ways to fix the seed manually. For PL, we use <code>pl.seed_everything(seed)</code> . See the docs <a href=\"https://pytorch-lightning.readthedocs.io/en/0.7.6/api/pytorch_lightning.trainer.seed.html\">here</a>.</p>\n<blockquote>\n<p>Note: in other libraries you would use something like: <code>np.random.seed()</code> or <code>torch.manual_seed()</code> </p>\n</blockquote>\n<h2><strong>Implementation</strong></h2>\n<p>Find the full code for this and other tutorials <a href=\"https://github.com/aimhubio/tutorials/tree/main/fixed-seed\">here</a>.</p>\n<pre><code>import torch\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision.datasets import CIFAR10\nfrom torchvision.models import resnet18\nfrom torchvision import transforms\nimport pytorch_lightning as pl\nfrom aim.pytorch_lightning import AimLogger\n\nclass ImageClassifierModel(pl.LightningModule):\n\n    def __init__(self, seed, lr, optimizer):\n        super(ImageClassifierModel, self).__init__()\n        pl.seed_everything(seed)\n        # This fixes a seed for all the modules used by pytorch-lightning\n        # Note: using random.seed(seed) is not enough, there are multiple\n        # other seeds like hash seed, seed for numpy etc.\n        self.lr = lr\n        self.optimizer = optimizer\n        self.total_classified = 0\n        self.correctly_classified = 0\n        self.model = resnet18(pretrained = True, progress = True)\n        self.model.fc = torch.nn.Linear(in_features=512, out_features=10, bias=True)\n        # changing the last layer from 1000 out_features to 10 because the model\n        # is pretrained on ImageNet which has 1000 classes but CIFAR10 has 10\n        self.model.to('cuda') # moving the model to cuda\n\n    def train_dataloader(self):\n        # makes the training dataloader\n        train_ds = CIFAR10('.', train = True, transform = transforms.ToTensor(), download = True)\n        train_loader = DataLoader(train_ds, batch_size=32)\n        return train_loader\n        \n    def val_dataloader(self):\n        # makes the validation dataloader\n        val_ds = CIFAR10('.', train = False, transform = transforms.ToTensor(), download = True)\n        val_loader = DataLoader(val_ds, batch_size=32)\n        return val_loader\n\n    def forward(self, x):\n        return self.model.forward(x)\n\n    def training_step(self, batch, batch_nb):\n        x, y = batch\n        y_hat = self.model(x)\n        loss = F.cross_entropy(y_hat, y)\n        # calculating the cross entropy loss on the result\n        self.log('train_loss', loss)\n        # logging the loss with \"train_\" prefix\n        return loss\n\n    def validation_step(self, batch, batch_nb):\n        x, y = batch\n        y_hat = self.model(x)\n        loss = F.cross_entropy(y_hat, y)\n        # calculating the cross entropy loss on the result\n        self.total_classified += y.shape[0]\n        self.correctly_classified += (y_hat.argmax(1) == y).sum().item()\n        # Calculating total and correctly classified images to determine the accuracy later\n        self.log('val_loss', loss) \n        # logging the loss with \"val_\" prefix\n        return loss\n\n    def validation_epoch_end(self, results):\n        accuracy = self.correctly_classified / self.total_classified\n        self.log('val_accuracy', accuracy)\n        # logging accuracy\n        self.total_classified = 0\n        self.correctly_classified = 0\n        return accuracy\n\n    def configure_optimizers(self):\n        # Choose an optimizer and set up a learning rate according to hyperparameters\n        if self.optimizer == 'Adam':\n            return torch.optim.Adam(self.parameters(), lr=self.lr)\n        elif self.optimizer == 'SGD':\n            return torch.optim.SGD(self.parameters(), lr=self.lr)\n        else:\n            raise NotImplementedError\n\nif __name__ == \"__main__\":\n\n    seeds = [47, 881, 123456789]\n    lrs = [0.1, 0.01]\n    optimizers = ['SGD', 'Adam']\n\n    for seed in seeds:\n        for optimizer in optimizers:\n            for lr in lrs:\n                # choosing one set of hyperparaameters from the ones above\n            \n                model = ImageClassifierModel(seed, lr, optimizer)\n                # initializing the model we will train with the chosen hyperparameters\n\n                aim_logger = AimLogger(\n                    experiment='resnet18_classification',\n                    train_metric_prefix='train_',\n                    val_metric_prefix='val_',\n                )\n                aim_logger.log_hyperparams({\n                    'lr': lr,\n                    'optimizer': optimizer,\n                    'seed': seed\n                })\n                # initializing the aim logger and logging the hyperparameters\n\n                trainer = pl.Trainer(\n                    logger=aim_logger,\n                    gpus=1,\n                    max_epochs=5,\n                    progress_bar_refresh_rate=1,\n                    log_every_n_steps=10,\n                    check_val_every_n_epoch=1)\n                # making the pytorch-lightning trainer\n\n                trainer.fit(model)\n                # training the model\n</code></pre>\n<h2>Analyzing the Training Runs</h2>\n<p>After each set of training runs you need to analyze the results/logs. Use Aim to group the runs by metrics/hyper-parameters (this can be done both on Explore and Dashboard after <a href=\"https://aimstack.io/mlops-tools-aim-1-3-5-activity-view-and-x-axis-alignment/\">Aim 1.3.5 release</a>) and have multiple charts of different metrics on the same screen.</p>\n<p>Do the following steps to see the different effects of the optimizers</p>\n<ul>\n<li>Go to dashboard, explore by experiment</li>\n<li>Add loss to <code>SELECT</code> and divide into subplots by metric</li>\n<li>Group by experiment to make all metrics of similar color</li>\n<li>Group by style by optimizer to see different optimizers on loss and accuracy and its effects</li>\n</ul>\n<p>Here is how it looks on Aim:</p>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2022/02/10.gif\" alt=\"\"></p>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2022/02/11.png\" alt=\"\"></p>\n<p>From the final result it is clear that the SGD (broken lines) optimizer has achieved higher accuracy and lower loss during the training.</p>\n<p>If you apply the same settings to the learning rate, this is the result:</p>\n<h2>For the next step to analyze how learning rate affects the experiments, do the following steps:</h2>\n<ul>\n<li>Remove both previous groupings</li>\n<li>Group by color by learning rate</li>\n</ul>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2022/02/12.gif\" alt=\"\"></p>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2022/02/13.png\" alt=\"\"></p>\n<p>As you can see, the purple lines (lr = 0.01) represent significantly lower loss and higher accuracy.</p>\n<p>We showed that in this case, the choice of the optimizer and learning rate is not dependent on the random seed and it is safe to say that the SGD optimizer with a 0.01 learning rate is the best choice we can make.</p>\n<p>On top of this, if we also add grouping by style by optimizer:</p>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2022/02/24.gif\" alt=\"\"></p>\n<p><img src=\"https://aimstack.io/wp-content/uploads/2022/02/25.png\" alt=\"\"></p>\n<p>Now, it is obvious that the the runs with SGD optimizer and <code>lr=0.01</code> (green, broken lines) are the best choices for all the seeds we have tried.</p>\n<p>Fixing random seeds is a useful technique that can help step-up your hyper-parameter tuning. This is how to use Aim and PyTorch Lightning to tune hyper-parameters with a fixed seed.</p>\n<h2>Learn More</h2>\n<p>If you find Aim useful, support us and <a href=\"https://github.com/aimhubio/aim\">star the project</a> on GitHub. Join the <a href=\"https://aimstack.slack.com/?redir=%2Fssb%2Fredirect\">Aim community</a> and share more about your use-cases and how we can improve Aim to suit them.</p>"},"_id":"how-to-tune-hyperparams-with-fixed-seeds-using-pytorch-lightning-and-aim.md","_raw":{"sourceFilePath":"how-to-tune-hyperparams-with-fixed-seeds-using-pytorch-lightning-and-aim.md","sourceFileName":"how-to-tune-hyperparams-with-fixed-seeds-using-pytorch-lightning-and-aim.md","sourceFileDir":".","contentType":"markdown","flattenedPath":"how-to-tune-hyperparams-with-fixed-seeds-using-pytorch-lightning-and-aim"},"type":"Post"}]},"__N_SSG":true}